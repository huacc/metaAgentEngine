# 知识提取-实验进展

# 0121

1、agent1强调伪相关性等特征

```plaintext


# ==========================================
# 1. 配置中心
# ==========================================
CONFIG = {
    "API_KEY": "sk-EIB06AaO2RkB2hKAHpb6cgn1neIAERjVz5vawh2T6TDGUCz2", 
    "BASE_URL": "https://www.dmxapi.cn/v1",  
    "INDUSTRY_TOPIC": "憎恶的表情图片", 
    "PATHS": {
        "TRAIN_POS": "./训练集憎恶正例",
        "TRAIN_NEG": "./训练集憎恶负例",
        "TEST_POS": "./测试集憎恶正例",
        "TEST_NEG": "./测试集憎恶负例",
    },
    "MODEL": "Qwen3-VL-235B-A22B-Instruct" 
}


# 初始化客户端
client = OpenAI(api_key=CONFIG["API_KEY"].strip(), base_url=CONFIG["BASE_URL"].strip())

# ==========================================
# 2. 工具函数
# ==========================================
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def load_images_safe(folder_path, label):
    """安全读取图片并返回base64列表"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        print(f"⚠️ 文件夹已创建但目前为空: {folder_path}，请放入{label}图片后重新运行。")
        return []
    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    print(f"📂 已加载 {label}: {len(files)} 张图片")
    # 限制训练集读取张数防止Token溢出，测试集不限
    limit = 8 if "训练" in label else 100
    return [encode_image(os.path.join(folder_path, f)) for f in files[:limit]]

def parse_score_json(json_str):
    """鲁棒的JSON解析，兼容中英文键名"""
    try:
        d = json.loads(json_str)
        scores_part = d.get("scores", d)
        def find_s(keys):
            for k, v in scores_part.items():
                if any(ik in k.lower() for ik in keys): return v
            return 0
        return {
            "logic": find_s(["logic", "逻辑"]),
            "relevance": find_s(["relevance", "相关", "业务"]),
            "completeness": find_s(["completeness", "完备", "覆盖"]),
            "operability": find_s(["operability", "操作", "执行"]),
            "total": d.get("total_score", d.get("总分", 0))
        }
    except:
        return {"logic":0, "relevance":0, "completeness":0, "operability":0, "total":0}

# ==========================================
# 3. 核心判定逻辑 (Agent 0, 4)
# ==========================================
def perform_test(rules_text, pos_list, neg_list, is_zero_shot=False):
    """在测试集上运行P/R测试"""
    tp, fp, tn, fn = 0, 0, 0, 0
    if is_zero_shot:
        prompt = f"# ROLE: 通用视觉判定专家\n# CONTEXT: 仅凭常识判定图片是否符合主题：{CONFIG['INDUSTRY_TOPIC']}。\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"
    else:
        prompt = f"# ROLE: 你是一个规则执行官，你需要依照{rules_text}判断图片是否符合主题【{CONFIG['INDUSTRY_TOPIC']}。\n# RULE: {rules_text}\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"

    for img in pos_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): tp += 1
        else: fn += 1
    for img in neg_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): fp += 1
        else: tn += 1
    
    p = tp/(tp+fp) if (tp+fp)>0 else 0
    r = tp/(tp+fn) if (tp+fn)>0 else 0
    return p, r

# ==========================================
# 4. 主工作流
# ==========================================
def run_workflow():
    # A. 数据加载
    print("🎬 正在初始化数据...")
    train_pos = load_images_safe(CONFIG["PATHS"]["TRAIN_POS"], "训练集正例")
    train_neg = load_images_safe(CONFIG["PATHS"]["TRAIN_NEG"], "训练集负例")
    test_pos = load_images_safe(CONFIG["PATHS"]["TEST_POS"], "测试集正例")
    test_neg = load_images_safe(CONFIG["PATHS"]["TEST_NEG"], "测试集负例")

    if not train_pos or not train_neg or not test_pos or not test_neg:
        print("🛑 错误：文件夹图片不足，请准备好图片后再运行。")
        return

    # --- 阶段 0: 零启动测试 ---
    print("🔍 阶段 0: 零启动测试（基于测试集）...")
    zs_p, zs_r = perform_test(None, test_pos, test_neg, is_zero_shot=True)

    # --- 阶段 1: Agent 1 (初始规则) ---
    print("🤖 阶段 1: Agent 1 提炼初始规则...")
    prompt1 = f"""
    # ROLE
    - 你是一名资深的【计算机视觉特征工程专家】与【行业逻辑架构师】。
    - 你的任务是：基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。

    # LOGIC PHILOSOPHY
    - **保留潜在元素**：即使某个特征在负样本中也存在，只要它可能是构成判定组合的一部分，就必须保留。
    - **证伪驱动修正**：将正样本中提取的“初版规则”放在负样本中运行，若误判，则通过增加约束条件（AND/NOT）来修正，而非直接删除特征。
    - **最小化路径**：在确保 100% 区分正负样本的前提下，规则描述应尽可能简洁。
   
    # ATTENTION
    - 逻辑一致性：规则不应存在内部矛盾
    - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - 伪相关性：规则不应包含与【{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
    - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

   
    # INPUT
    - **Positive Samples**: 符合【{CONFIG['INDUSTRY_TOPIC']}】标准的图片集。
    - **Negative Samples**: 不符合标准的干扰项图片集。

    ---

    # EXPLICIT WORKFLOW

    ## STEP 1：正样本特征提取与规则初探 (Hypothesis Generation)
    - **视觉原点挖掘**：观察所有正样本，提取出所有显著的视觉元素（特征 A, B, C...）。
    - **内部共性组合**：分析这些特征如何组合（单点或多点组合）能覆盖 100% 的正样本。
    - **建立初版规则**：例如：“规则1 = A + B” 或 “规则2 = C”。

    ## STEP 2：负样本冲突测试 (Stress Testing & Conflict Detection)
    - **规则代入**：将 STEP 1 建立的初版规则逐一在负样本中测试。
    - **冲突记录**：如果负样本也触发了某条规则（即出现了 False Positive），详细记录该负样本在对应特征上的细微差异。
    - **识别判别增量**：寻找能将“触发规则的负样本”排除掉的额外视觉特征 D（即：在正样本中 A+B 且具备 D 属性，而负样本只有 A+B 但不具备 D）。

    ## STEP 3：动态修正与逻辑收敛 (Rule Refinement)
    - **规则打补丁**：利用 STEP 2 发现的增量，对初版规则进行加固。
      - *修正前*：Rule = A + B
      - *修正后*：Rule = A + B + (具备 D 属性/排除 E 环境)
    - **结构压缩**：检查修正后的规则，如果多个规则可以合并，或者某个特征在加入新约束后变得冗余，则进行精简。

    ## STEP 4：生成最终判定矩阵 (Final Synthesis)
    - 整理出一组相互独立且互补的规则，每条规则都是一条从视觉证据到判定的完整路径。

    ---

    # OUTPUT FORMAT (STRICT JSON ONLY)

    ```json
{{
  "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
  "visual_cues": [
    {{
      "cue_id": "C1",
      "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
    }}
  ],
  "decision_rules": [
    {{
      "rule_id": "R1",
      "logic": "C1 AND C2",
      "target": "POSITIVE"
    }},
    {{
      "rule_id": "R2",
      "logic": "C3 AND (NOT C4)",
      "target": "POSITIVE"
    }}
  ]
}}
        """
    c1 = [{"type": "text", "text": prompt1}, {"type": "text", "text": "=== 训练集正例 ==="}]
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c1.append({"type": "text", "text": "=== 训练集负例 ==="})
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])
    
    r1_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": c1}], response_format={"type": "json_object"})
    r1_content = r1_res.choices[0].message.content

    # --- 阶段 2: Agent 2 (挑战者) ---
    print("🕵️ 阶段 2: Agent 2 开始审计规则逻辑与伪相关性...")
    # 1. 优化后的通用 Prompt
    prompt2 = f"""
    # ROLE
    - 你是一个逻辑漏洞审计员 (红队成员)
    - 你需要审核**行业逻辑架构师**从图像集中提取的【分类规则】。你的目标是发现规则中的逻辑漏洞、过度拟合以及“伪相关性”（Spurious Correlations）。

    # DEFINITION 
    - 【训练集正例】：完全符合目标类别的标准样本。
    - 【训练集负例】：不符合目标类别的样本，必须被规则准确排除。
    - **行业逻辑架构师**：其任务是基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    
    # INPUT_RULES: {r1_content}
    
    # WORKFLOW:
    ## Step 1: **对比观察**
    - 结合正例与负例图片，逐条审查 INPUT_RULES。
    
    ##Step 2: **多维度审计**：
    - 从以下维度评价INPUT_RULES，并针对存在问题的部分提出质疑和反驳
        - 逻辑一致性：规则不应存在内部矛盾
        - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
        - 伪相关性：规则不应包含与【{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
        - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    # CONSTRAITS:
    - 你必须严格围绕INPUT_RULES和正负例图片进行分析，不要过度依靠你关于【{CONFIG['INDUSTRY_TOPIC']}】的个性化解度
    - 你的每一条反驳必须有理有据。
    - 至少输出一条反驳，不得输出为空。
    

    # OUTPUT STANDARD:
    必须以 JSON 格式输出，包含 challenges 数组，结构如下：
    {{
      "challenges": [
        {{
          "target_rule": "被质疑的原始规则条目",
          "logic_error_type": "逻辑一致性 / 有效性/ 伪相关性/过度拟合",
          "reasoning": "解释为什么利用该特征作为判定依据是不可靠的。"
        }}
      ]
    }}
    """

    # 2. 构建包含图像序列的输入
    c2 = [{"type": "text", "text": prompt2}]

    # 辅助说明，确保模型明确图像的标签身份
    c2.append({"type": "text", "text": "=== 待审计的【训练集正例】 (Target Category Samples) ==="})
    for img_data in train_pos:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    c2.append({"type": "text", "text": "=== 待审计的【训练集负例】 (Negative Samples) ==="})
    for img_data in train_neg:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    # 3. 执行 API 调用
    r2_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c2}], 
        response_format={"type": "json_object"}
    )

    r2_content = r2_res.choices[0].message.content

    # --- 阶段 3: Agent 3 (合成最终规则) ---
    print("⚖️ 阶段 3: Agent 3 合成最终规则...")
    prompt3 = f"""
    # ROLE
    - 你是一位行业标准首席架构师
    - 你需要判断挑战意见的合理性，并再次对照原始图片，优化和调整初步规则，形成最终的行业判别准则。
    # Definition：
    - **初步规则**：由一位行业逻辑架构师对比正负样本，发现的判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    - **挑战意见**：由一位审计人员对比正负样本和**初步规则**提出的挑战性建议。
    - **逻辑一致性**：规则不应存在内部矛盾
    - **有效性**：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - **伪相关性**：规则不应包含与{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
    - **过度拟合**：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    
    # INPUT_INITIAL: {r1_content}
    # INPUT_CHALLENGES: {r2_content}
    
    # WORKFLOW: 
    ## Step 1: 综合理解
    - 对照【训练集正例】与【训练集负例】图片，全面理解阅读**初步规则 (INPUT_INITIAL)**、**挑战意见 (INPUT_CHALLENGES)**。
    ## Step 2: **挑战意见**审核
    - 从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度，理性判断**挑战意见**的合理性
    - 仅保留“挑战意见”中合理的部分。
    ## Step 3: **行业判别标准**生成
    - 结合**挑战意见**中合理的部分，优化**初步规则**，形成**行业判别标准**。
    ## Step 4: 双重校验
    - 再次基于【训练集正例】与【训练集负例】图片，从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度评价**行业判别标准**。若符合标准则输出；若不符合标准则继续优化。
    
    # CONSTRAITS:
    - 严禁盲信**挑战意见**的观点，你是老板，你优最终选择权。

    # OUTPUT STANDARD: 以JSON 格式输出 final_rules 数组，结构如下：
    {{
      "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
      "visual_cues": [
        {{
          "cue_id": "C1",
          "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
        }}
      ],
      "decision_rules": [
        {{
          "rule_id": "R1",
          "logic": "C1 AND C2",
          "target": "POSITIVE"
        }},
        {{
          "rule_id": "R2",
          "logic": "C3 AND (NOT C4)",
          "target": "POSITIVE"
        }}
      ]
    }}
        """

    # 构建包含图片的输入
    c3 = [{"type": "text", "text": prompt3}, {"type": "text", "text": "=== 参照对比：训练集正例 ==="}]
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c3.append({"type": "text", "text": "=== 参照对比：训练集负例 ==="})
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])

    r3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c3}], 
        response_format={"type": "json_object"}
    )
    r3_content = r3_res.choices[0].message.content

# ... (后续阶段 4 和结果汇总代码保持不变)

    # --- 阶段 4: Agent 4 评估 ---
    print("📊 阶段 4: Agent 4 进行审计与效能实测...")
    
    # 定义结构化 Prompt，明确 Key 的名称以防解析失败
    score_p_template = """
    # ROLE: 规则质量评估专家
    # WORKFLOW: 
    请对以下规则进行四个维度的量化打分（每个维度满分 25 分，总分 100 分）：
    1. 逻辑一致性：规则内部是否存在矛盾。
    2. 业务相关性：是否有效剔除了与主题无关的噪音（如背景、无关杂物）。
    3. 完备性：规则是否覆盖了区分正负样本的核心视觉信号。
    4. 可操作性：规则描述是否清晰，能否被第三方准确执行。
    
    # INPUT: 
    {rules_to_score}
    
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，不得包含解释文字。必须包含 "scores" 字典，其 Key 必须严格为: 
    "logic", "relevance", "completeness", "operability"。此外包含 "total_score"。
    """

    # 判定并生成初始规则评分 (使用 f-string 避免 .format 错误)
    s1_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r1_content)}"}], 
        response_format={"type":"json_object"}
    )
    s1_json = s1_res.choices[0].message.content
    
    # 判定并生成最终规则评分
    s3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r3_content)}"}], 
        response_format={"type":"json_object"}
    )
    s3_json = s3_res.choices[0].message.content

    # 解析数据 (确保你的 parse_score_json 函数能处理 logic, relevance 等 Key)
    s1_data = parse_score_json(s1_json)
    s3_data = parse_score_json(s3_json)
    
    # 效能实测 (仅基于测试集)
    r1_p, r1_r = perform_test(r1_content, test_pos, test_neg)
    r3_p, r3_r = perform_test(r3_content, test_pos, test_neg)

    # ==========================================
    # 5. 结果汇总输出
    # ==========================================
    print("\n" + "★"*40)
    print("【1. 智能体 1：初始规则内容】")
    print(r1_content)
    print("\n【2. 智能体 2：挑战意见】")
    print(r2_content)
    print("\n【3. 智能体 3：最终合成规则内容】")
    print(r3_content)
    
    print("\n【4. 综合进化对比表 (指标基于测试集)】")
    print("-" * 95)
    print(f"{'评估维度':<16} | {'零启动(Zero-Shot)':<18} | {'初始规则(Initial)':<18} | {'最终规则(Final)':<18}")
    print("-" * 95)
    
    rows = [("逻辑一致性","logic"), ("业务相关性","relevance"), ("完备性","completeness"), ("可操作性","operability"), ("内容总分","total")]
    for name, key in rows:
        v1, v3 = s1_data[key], s3_data[key]
        print(f"{name:<16} | {'--':<18} | {v1:<18} | {v3:<18}")
    
    print("-" * 95)
    print(f"{'精确率 (Prec.)':<16} | {zs_p:<18.2%} | {r1_p:<18.2%} | {r3_p:<18.2%}")
    print(f"{'召回率 (Rec.)':<16} | {zs_r:<18.2%} | {r1_r:<18.2%} | {r3_r:<18.2%}")
    print("-" * 95)
 
run_workflow()
```

![截屏2026-01-21 01.11.17.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/bbb88103-5961-4e09-af6e-0002d917e842.png)

2、最终判断prompt优化

```plaintext


# ==========================================
# 1. 配置中心
# ==========================================
CONFIG = {
    "API_KEY": "sk-EIB06AaO2RkB2hKAHpb6cgn1neIAERjVz5vawh2T6TDGUCz2", 
    "BASE_URL": "https://www.dmxapi.cn/v1",  
    "INDUSTRY_TOPIC": "憎恶的表情图片", 
    "PATHS": {
        "TRAIN_POS": "./训练集憎恶正例",
        "TRAIN_NEG": "./训练集憎恶负例",
        "TEST_POS": "./测试集憎恶正例",
        "TEST_NEG": "./测试集憎恶负例",
    },
    "MODEL": "Qwen3-VL-235B-A22B-Instruct" 
}


# 初始化客户端
client = OpenAI(api_key=CONFIG["API_KEY"].strip(), base_url=CONFIG["BASE_URL"].strip())

# ==========================================
# 2. 工具函数
# ==========================================
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def load_images_safe(folder_path, label):
    """安全读取图片并返回base64列表"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        print(f"⚠️ 文件夹已创建但目前为空: {folder_path}，请放入{label}图片后重新运行。")
        return []
    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    print(f"📂 已加载 {label}: {len(files)} 张图片")
    # 限制训练集读取张数防止Token溢出，测试集不限
    limit = 8 if "训练" in label else 100
    return [encode_image(os.path.join(folder_path, f)) for f in files[:limit]]

def parse_score_json(json_str):
    """鲁棒的JSON解析，兼容中英文键名"""
    try:
        d = json.loads(json_str)
        scores_part = d.get("scores", d)
        def find_s(keys):
            for k, v in scores_part.items():
                if any(ik in k.lower() for ik in keys): return v
            return 0
        return {
            "logic": find_s(["logic", "逻辑"]),
            "relevance": find_s(["relevance", "相关", "业务"]),
            "completeness": find_s(["completeness", "完备", "覆盖"]),
            "operability": find_s(["operability", "操作", "执行"]),
            "total": d.get("total_score", d.get("总分", 0))
        }
    except:
        return {"logic":0, "relevance":0, "completeness":0, "operability":0, "total":0}

# ==========================================
# 3. 核心判定逻辑 (Agent 0, 4)
# ==========================================
def perform_test(rules_text, pos_list, neg_list, is_zero_shot=False):
    """在测试集上运行P/R测试"""
    tp, fp, tn, fn = 0, 0, 0, 0
    if is_zero_shot:
        prompt = f"# ROLE: 通用视觉判定专家\n# CONTEXT: 仅凭常识判定图片是否符合主题：{CONFIG['INDUSTRY_TOPIC']}。\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"
    else:
        prompt = f"# ROLE: 你是一个规则执行官，你首先需要依照{rules_text}判断图片是否符合主题【{CONFIG['INDUSTRY_TOPIC']}；随后再进行一次检查，然后再给出最终答案。注意：符合规则的一定是正例。但不符合规则的例子你需要脱离规则并运用常识进行二次判断，当两次判断负例时你可以认为这是负例；当运用常识你认为是正例时，你需要对该案例进行打分，当结合常识和{rules_text}，你发现该案例符合{CONFIG['INDUSTRY_TOPIC']}场景的可能性大于50%，则为正例，否则为负例。\n# RULE: {rules_text}\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"

    for img in pos_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): tp += 1
        else: fn += 1
    for img in neg_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): fp += 1
        else: tn += 1
    
    p = tp/(tp+fp) if (tp+fp)>0 else 0
    r = tp/(tp+fn) if (tp+fn)>0 else 0
    return p, r

# ==========================================
# 4. 主工作流
# ==========================================
def run_workflow():
    # A. 数据加载
    print("🎬 正在初始化数据...")
    train_pos = load_images_safe(CONFIG["PATHS"]["TRAIN_POS"], "训练集正例")
    train_neg = load_images_safe(CONFIG["PATHS"]["TRAIN_NEG"], "训练集负例")
    test_pos = load_images_safe(CONFIG["PATHS"]["TEST_POS"], "测试集正例")
    test_neg = load_images_safe(CONFIG["PATHS"]["TEST_NEG"], "测试集负例")

    if not train_pos or not train_neg or not test_pos or not test_neg:
        print("🛑 错误：文件夹图片不足，请准备好图片后再运行。")
        return

    # --- 阶段 0: 零启动测试 ---
    print("🔍 阶段 0: 零启动测试（基于测试集）...")
    zs_p, zs_r = perform_test(None, test_pos, test_neg, is_zero_shot=True)

    # --- 阶段 1: Agent 1 (初始规则) ---
    print("🤖 阶段 1: Agent 1 提炼初始规则...")
    prompt1 = f"""
    # ROLE
    - 你是一名资深的【计算机视觉特征工程专家】与【行业逻辑架构师】。
    - 你的任务是：基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。

    # LOGIC PHILOSOPHY
    - **保留潜在元素**：即使某个特征在负样本中也存在，只要它可能是构成判定组合的一部分，就必须保留。
    - **证伪驱动修正**：将正样本中提取的“初版规则”放在负样本中运行，若误判，则通过增加约束条件（AND/NOT）来修正，而非直接删除特征。
    - **最小化路径**：在确保 100% 区分正负样本的前提下，规则描述应尽可能简洁。
   
    # ATTENTION
    - 逻辑一致性：规则不应存在内部矛盾
    - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - 伪相关性：规则不应包含与【{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
    - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

   
    # INPUT
    - **Positive Samples**: 符合【{CONFIG['INDUSTRY_TOPIC']}】标准的图片集。
    - **Negative Samples**: 不符合标准的干扰项图片集。

    ---

    # EXPLICIT WORKFLOW

    ## STEP 1：正样本特征提取与规则初探 (Hypothesis Generation)
    - **视觉原点挖掘**：观察所有正样本，提取出所有显著的视觉元素（特征 A, B, C...）。
    - **内部共性组合**：分析这些特征如何组合（单点或多点组合）能覆盖 100% 的正样本。
    - **建立初版规则**：例如：“规则1 = A + B” 或 “规则2 = C”。

    ## STEP 2：负样本冲突测试 (Stress Testing & Conflict Detection)
    - **规则代入**：将 STEP 1 建立的初版规则逐一在负样本中测试。
    - **冲突记录**：如果负样本也触发了某条规则（即出现了 False Positive），详细记录该负样本在对应特征上的细微差异。
    - **识别判别增量**：寻找能将“触发规则的负样本”排除掉的额外视觉特征 D（即：在正样本中 A+B 且具备 D 属性，而负样本只有 A+B 但不具备 D）。

    ## STEP 3：动态修正与逻辑收敛 (Rule Refinement)
    - **规则打补丁**：利用 STEP 2 发现的增量，对初版规则进行加固。
      - *修正前*：Rule = A + B
      - *修正后*：Rule = A + B + (具备 D 属性/排除 E 环境)
    - **结构压缩**：检查修正后的规则，如果多个规则可以合并，或者某个特征在加入新约束后变得冗余，则进行精简。

    ## STEP 4：生成最终判定矩阵 (Final Synthesis)
    - 整理出一组相互独立且互补的规则，每条规则都是一条从视觉证据到判定的完整路径。

    ---

    # OUTPUT FORMAT (STRICT JSON ONLY)

    ```json
{{
  "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
  "visual_cues": [
    {{
      "cue_id": "C1",
      "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
    }}
  ],
  "decision_rules": [
    {{
      "rule_id": "R1",
      "logic": "C1 AND C2",
      "target": "POSITIVE"
    }},
    {{
      "rule_id": "R2",
      "logic": "C3 AND (NOT C4)",
      "target": "POSITIVE"
    }}
  ]
}}
        """
    c1 = [{"type": "text", "text": prompt1}, {"type": "text", "text": "=== 训练集正例 ==="}]
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c1.append({"type": "text", "text": "=== 训练集负例 ==="})
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])
    
    r1_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": c1}], response_format={"type": "json_object"})
    r1_content = r1_res.choices[0].message.content

    # --- 阶段 2: Agent 2 (挑战者) ---
    print("🕵️ 阶段 2: Agent 2 开始审计规则逻辑与伪相关性...")
    # 1. 优化后的通用 Prompt
    prompt2 = f"""
    # ROLE
    - 你是一个逻辑漏洞审计员 (红队成员)
    - 你需要审核**行业逻辑架构师**从图像集中提取的【分类规则】。你的目标是发现规则中的逻辑漏洞、过度拟合以及“伪相关性”（Spurious Correlations）。

    # DEFINITION 
    - 【训练集正例】：完全符合目标类别的标准样本。
    - 【训练集负例】：不符合目标类别的样本，必须被规则准确排除。
    - **行业逻辑架构师**：其任务是基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    
    # INPUT_RULES: {r1_content}
    
    # WORKFLOW:
    ## Step 1: **对比观察**
    - 结合正例与负例图片，逐条审查 INPUT_RULES。
    
    ##Step 2: **多维度审计**：
    - 从以下维度评价INPUT_RULES，并针对存在问题的部分提出质疑和反驳
        - 逻辑一致性：规则不应存在内部矛盾
        - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
        - 伪相关性：规则不应包含与【{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
        - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    # CONSTRAITS:
    - 你必须严格围绕INPUT_RULES和正负例图片进行分析，不要过度依靠你关于【{CONFIG['INDUSTRY_TOPIC']}】的个性化解度
    - 你的每一条反驳必须有理有据。
    - 至少输出一条反驳，不得输出为空。
    

    # OUTPUT STANDARD:
    必须以 JSON 格式输出，包含 challenges 数组，结构如下：
    {{
      "challenges": [
        {{
          "target_rule": "被质疑的原始规则条目",
          "logic_error_type": "逻辑一致性 / 有效性/ 伪相关性/过度拟合",
          "reasoning": "解释为什么利用该特征作为判定依据是不可靠的。"
        }}
      ]
    }}
    """

    # 2. 构建包含图像序列的输入
    c2 = [{"type": "text", "text": prompt2}]

    # 辅助说明，确保模型明确图像的标签身份
    c2.append({"type": "text", "text": "=== 待审计的【训练集正例】 (Target Category Samples) ==="})
    for img_data in train_pos:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    c2.append({"type": "text", "text": "=== 待审计的【训练集负例】 (Negative Samples) ==="})
    for img_data in train_neg:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    # 3. 执行 API 调用
    r2_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c2}], 
        response_format={"type": "json_object"}
    )

    r2_content = r2_res.choices[0].message.content

    # --- 阶段 3: Agent 3 (合成最终规则) ---
    print("⚖️ 阶段 3: Agent 3 合成最终规则...")
    prompt3 = f"""
    # ROLE
    - 你是一位行业标准首席架构师
    - 你需要判断挑战意见的合理性，并再次对照原始图片，优化和调整初步规则，形成最终的行业判别准则。
    # Definition：
    - **初步规则**：由一位行业逻辑架构师对比正负样本，发现的判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    - **挑战意见**：由一位审计人员对比正负样本和**初步规则**提出的挑战性建议。
    - **逻辑一致性**：规则不应存在内部矛盾
    - **有效性**：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - **伪相关性**：规则不应包含与{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
    - **过度拟合**：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    
    # INPUT_INITIAL: {r1_content}
    # INPUT_CHALLENGES: {r2_content}
    
    # WORKFLOW: 
    ## Step 1: 综合理解
    - 对照【训练集正例】与【训练集负例】图片，全面理解阅读**初步规则 (INPUT_INITIAL)**、**挑战意见 (INPUT_CHALLENGES)**。
    ## Step 2: **挑战意见**审核
    - 从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度，理性判断**挑战意见**的合理性
    - 仅保留“挑战意见”中合理的部分。
    ## Step 3: **行业判别标准**生成
    - 结合**挑战意见**中合理的部分，优化**初步规则**，形成**行业判别标准**。
    ## Step 4: 双重校验
    - 再次基于【训练集正例】与【训练集负例】图片，从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度评价**行业判别标准**。若符合标准则输出；若不符合标准则继续优化。
    
    # CONSTRAITS:
    - 严禁盲信**挑战意见**的观点，你是老板，你优最终选择权。

    # OUTPUT STANDARD: 以JSON 格式输出 final_rules 数组，结构如下：
    {{
      "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
      "visual_cues": [
        {{
          "cue_id": "C1",
          "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
        }}
      ],
      "decision_rules": [
        {{
          "rule_id": "R1",
          "logic": "C1 AND C2",
          "target": "POSITIVE"
        }},
        {{
          "rule_id": "R2",
          "logic": "C3 AND (NOT C4)",
          "target": "POSITIVE"
        }}
      ]
    }}
        """

    # 构建包含图片的输入
    c3 = [{"type": "text", "text": prompt3}, {"type": "text", "text": "=== 参照对比：训练集正例 ==="}]
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c3.append({"type": "text", "text": "=== 参照对比：训练集负例 ==="})
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])

    r3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c3}], 
        response_format={"type": "json_object"}
    )
    r3_content = r3_res.choices[0].message.content

# ... (后续阶段 4 和结果汇总代码保持不变)

    # --- 阶段 4: Agent 4 评估 ---
    print("📊 阶段 4: Agent 4 进行审计与效能实测...")
    
    # 定义结构化 Prompt，明确 Key 的名称以防解析失败
    score_p_template = """
    # ROLE: 规则质量评估专家
    # WORKFLOW: 
    请对以下规则进行四个维度的量化打分（每个维度满分 25 分，总分 100 分）：
    1. 逻辑一致性：规则内部是否存在矛盾。
    2. 业务相关性：是否有效剔除了与主题无关的噪音（如背景、无关杂物）。
    3. 完备性：规则是否覆盖了区分正负样本的核心视觉信号。
    4. 可操作性：规则描述是否清晰，能否被第三方准确执行。
    
    # INPUT: 
    {rules_to_score}
    
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，不得包含解释文字。必须包含 "scores" 字典，其 Key 必须严格为: 
    "logic", "relevance", "completeness", "operability"。此外包含 "total_score"。
    """

    # 判定并生成初始规则评分 (使用 f-string 避免 .format 错误)
    s1_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r1_content)}"}], 
        response_format={"type":"json_object"}
    )
    s1_json = s1_res.choices[0].message.content
    
    # 判定并生成最终规则评分
    s3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r3_content)}"}], 
        response_format={"type":"json_object"}
    )
    s3_json = s3_res.choices[0].message.content

    # 解析数据 (确保你的 parse_score_json 函数能处理 logic, relevance 等 Key)
    s1_data = parse_score_json(s1_json)
    s3_data = parse_score_json(s3_json)
    
    # 效能实测 (仅基于测试集)
    r1_p, r1_r = perform_test(r1_content, test_pos, test_neg)
    r3_p, r3_r = perform_test(r3_content, test_pos, test_neg)

    # ==========================================
    # 5. 结果汇总输出
    # ==========================================
    print("\n" + "★"*40)
    print("【1. 智能体 1：初始规则内容】")
    print(r1_content)
    print("\n【2. 智能体 2：挑战意见】")
    print(r2_content)
    print("\n【3. 智能体 3：最终合成规则内容】")
    print(r3_content)
    
    print("\n【4. 综合进化对比表 (指标基于测试集)】")
    print("-" * 95)
    print(f"{'评估维度':<16} | {'零启动(Zero-Shot)':<18} | {'初始规则(Initial)':<18} | {'最终规则(Final)':<18}")
    print("-" * 95)
    
    rows = [("逻辑一致性","logic"), ("业务相关性","relevance"), ("完备性","completeness"), ("可操作性","operability"), ("内容总分","total")]
    for name, key in rows:
        v1, v3 = s1_data[key], s3_data[key]
        print(f"{name:<16} | {'--':<18} | {v1:<18} | {v3:<18}")
    
    print("-" * 95)
    print(f"{'精确率 (Prec.)':<16} | {zs_p:<18.2%} | {r1_p:<18.2%} | {r3_p:<18.2%}")
    print(f"{'召回率 (Rec.)':<16} | {zs_r:<18.2%} | {r1_r:<18.2%} | {r3_r:<18.2%}")
    print("-" * 95)
 
run_workflow()
```

![截屏2026-01-21 01.43.39.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/d03e3316-d870-4c7d-9af6-b587f1d1c7d2.png)

3、增加准确率和召回率平衡的要求

```plaintext


# ==========================================
# 1. 配置中心
# ==========================================
CONFIG = {
    "API_KEY": "sk-EIB06AaO2RkB2hKAHpb6cgn1neIAERjVz5vawh2T6TDGUCz2", 
    "BASE_URL": "https://www.dmxapi.cn/v1",  
    "INDUSTRY_TOPIC": "憎恶的表情图片", 
    "PATHS": {
        "TRAIN_POS": "./训练集憎恶正例",
        "TRAIN_NEG": "./训练集憎恶负例",
        "TEST_POS": "./测试集憎恶正例",
        "TEST_NEG": "./测试集憎恶负例",
    },
    "MODEL": "Qwen3-VL-235B-A22B-Instruct" 
}


# 初始化客户端
client = OpenAI(api_key=CONFIG["API_KEY"].strip(), base_url=CONFIG["BASE_URL"].strip())

# ==========================================
# 2. 工具函数
# ==========================================
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def load_images_safe(folder_path, label):
    """安全读取图片并返回base64列表"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        print(f"⚠️ 文件夹已创建但目前为空: {folder_path}，请放入{label}图片后重新运行。")
        return []
    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    print(f"📂 已加载 {label}: {len(files)} 张图片")
    # 限制训练集读取张数防止Token溢出，测试集不限
    limit = 8 if "训练" in label else 100
    return [encode_image(os.path.join(folder_path, f)) for f in files[:limit]]

def parse_score_json(json_str):
    """鲁棒的JSON解析，兼容中英文键名"""
    try:
        d = json.loads(json_str)
        scores_part = d.get("scores", d)
        def find_s(keys):
            for k, v in scores_part.items():
                if any(ik in k.lower() for ik in keys): return v
            return 0
        return {
            "logic": find_s(["logic", "逻辑"]),
            "relevance": find_s(["relevance", "相关", "业务"]),
            "completeness": find_s(["completeness", "完备", "覆盖"]),
            "operability": find_s(["operability", "操作", "执行"]),
            "total": d.get("total_score", d.get("总分", 0))
        }
    except:
        return {"logic":0, "relevance":0, "completeness":0, "operability":0, "total":0}

# ==========================================
# 3. 核心判定逻辑 (Agent 0, 4)
# ==========================================
def perform_test(rules_text, pos_list, neg_list, is_zero_shot=False):
    """在测试集上运行P/R测试"""
    tp, fp, tn, fn = 0, 0, 0, 0
    if is_zero_shot:
        prompt = f"# ROLE: 通用视觉判定专家\n# CONTEXT: 仅凭常识判定图片是否符合主题：{CONFIG['INDUSTRY_TOPIC']}。\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"
    else:
        prompt = f"# ROLE: 你是一个规则执行官，你需要依照{rules_text}判断图片是否符合主题【{CONFIG['INDUSTRY_TOPIC']}。\n# RULE: {rules_text}\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"

    for img in pos_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): tp += 1
        else: fn += 1
    for img in neg_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): fp += 1
        else: tn += 1
    
    p = tp/(tp+fp) if (tp+fp)>0 else 0
    r = tp/(tp+fn) if (tp+fn)>0 else 0
    return p, r

# ==========================================
# 4. 主工作流
# ==========================================
def run_workflow():
    # A. 数据加载
    print("🎬 正在初始化数据...")
    train_pos = load_images_safe(CONFIG["PATHS"]["TRAIN_POS"], "训练集正例")
    train_neg = load_images_safe(CONFIG["PATHS"]["TRAIN_NEG"], "训练集负例")
    test_pos = load_images_safe(CONFIG["PATHS"]["TEST_POS"], "测试集正例")
    test_neg = load_images_safe(CONFIG["PATHS"]["TEST_NEG"], "测试集负例")

    if not train_pos or not train_neg or not test_pos or not test_neg:
        print("🛑 错误：文件夹图片不足，请准备好图片后再运行。")
        return

    # --- 阶段 0: 零启动测试 ---
    print("🔍 阶段 0: 零启动测试（基于测试集）...")
    zs_p, zs_r = perform_test(None, test_pos, test_neg, is_zero_shot=True)

    # --- 阶段 1: Agent 1 (初始规则) ---
    print("🤖 阶段 1: Agent 1 提炼初始规则...")
    prompt1 = f"""
    # ROLE
    - 你是一名资深的【计算机视觉特征工程专家】与【行业逻辑架构师】。
    - 你的任务是：基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。

    # LOGIC PHILOSOPHY
    - **保留潜在元素**：即使某个特征在负样本中也存在，只要它可能是构成判定组合的一部分，就必须保留。
    - **证伪驱动修正**：将正样本中提取的“初版规则”放在负样本中运行，若误判，则通过增加约束条件（AND/NOT）来修正，而非直接删除特征。
    - **最小化路径**：在确保 100% 区分正负样本的前提下，规则描述应尽可能简洁。
   
    # ATTENTION
    - 逻辑一致性：规则不应存在内部矛盾
    - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - 伪相关性：规则不应包含与【{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
    - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件
    - **重要指示**：你所提炼的规则既要尽可能召回所有的正例，又要尽可能避免错召不符合条件的案例。换言之，你需要维护精确率和召回率的平衡。
   
    # INPUT
    - **Positive Samples**: 符合【{CONFIG['INDUSTRY_TOPIC']}】标准的图片集。
    - **Negative Samples**: 不符合标准的干扰项图片集。

    ---

    # EXPLICIT WORKFLOW

    ## STEP 1：正样本特征提取与规则初探 (Hypothesis Generation)
    - **视觉原点挖掘**：观察所有正样本，提取出所有显著的视觉元素（特征 A, B, C...）。
    - **内部共性组合**：分析这些特征如何组合（单点或多点组合）能覆盖 100% 的正样本。
    - **建立初版规则**：例如：“规则1 = A + B” 或 “规则2 = C”。

    ## STEP 2：负样本冲突测试 (Stress Testing & Conflict Detection)
    - **规则代入**：将 STEP 1 建立的初版规则逐一在负样本中测试。
    - **冲突记录**：如果负样本也触发了某条规则（即出现了 False Positive），详细记录该负样本在对应特征上的细微差异。
    - **识别判别增量**：寻找能将“触发规则的负样本”排除掉的额外视觉特征 D（即：在正样本中 A+B 且具备 D 属性，而负样本只有 A+B 但不具备 D）。

    ## STEP 3：动态修正与逻辑收敛 (Rule Refinement)
    - **规则打补丁**：利用 STEP 2 发现的增量，对初版规则进行加固。
      - *修正前*：Rule = A + B
      - *修正后*：Rule = A + B + (具备 D 属性/排除 E 环境)
    - **结构压缩**：检查修正后的规则，如果多个规则可以合并，或者某个特征在加入新约束后变得冗余，则进行精简。
    
    
    ## STEP 4：生成最终判定矩阵 (Final Synthesis)
    - 整理出一组相互独立且互补的规则，每条规则都是一条从视觉证据到判定的完整路径。

    ---

    # OUTPUT FORMAT (STRICT JSON ONLY)

    ```json
{{
  "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
  "visual_cues": [
    {{
      "cue_id": "C1",
      "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
    }}
  ],
  "decision_rules": [
    {{
      "rule_id": "R1",
      "logic": "C1 AND C2",
      "target": "POSITIVE"
    }},
    {{
      "rule_id": "R2",
      "logic": "C3 AND (NOT C4)",
      "target": "POSITIVE"
    }}
  ]
}}
        """
    c1 = [{"type": "text", "text": prompt1}, {"type": "text", "text": "=== 训练集正例 ==="}]
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c1.append({"type": "text", "text": "=== 训练集负例 ==="})
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])
    
    r1_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": c1}], response_format={"type": "json_object"})
    r1_content = r1_res.choices[0].message.content

    # --- 阶段 2: Agent 2 (挑战者) ---
    print("🕵️ 阶段 2: Agent 2 开始审计规则逻辑与伪相关性...")
    # 1. 优化后的通用 Prompt
    prompt2 = f"""
    # ROLE
    - 你是一个逻辑漏洞审计员 (红队成员)
    - 你需要审核**行业逻辑架构师**从图像集中提取的【分类规则】。你的目标是发现规则中的逻辑漏洞、过度拟合以及“伪相关性”（Spurious Correlations）。

    # DEFINITION 
    - 【训练集正例】：完全符合目标类别的标准样本。
    - 【训练集负例】：不符合目标类别的样本，必须被规则准确排除。
    - **行业逻辑架构师**：其任务是基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    
    # INPUT_RULES: {r1_content}
    
    # WORKFLOW:
    ## Step 1: **对比观察**
    - 结合正例与负例图片，逐条审查 INPUT_RULES。
    
    ##Step 2: **多维度审计**：
    - 从以下维度评价INPUT_RULES，并针对存在问题的部分提出质疑和反驳
        - 逻辑一致性：规则不应存在内部矛盾
        - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
        - 伪相关性：规则不应包含与【{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
        - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    # CONSTRAITS:
    - 你必须严格围绕INPUT_RULES和正负例图片进行分析，不要过度依靠你关于【{CONFIG['INDUSTRY_TOPIC']}】的个性化解度
    - 你的每一条反驳必须有理有据。
    - 至少输出一条反驳，不得输出为空。
    - **重要指示**：你所提炼的建议既要尽可能帮助规则召回所有的正例，又要尽可能帮助规则避免错召不符合条件的案例。换言之，你需要维护精确率和召回率的平衡。
   
    

    # OUTPUT STANDARD:
    必须以 JSON 格式输出，包含 challenges 数组，结构如下：
    {{
      "challenges": [
        {{
          "target_rule": "被质疑的原始规则条目",
          "logic_error_type": "逻辑一致性 / 有效性/ 伪相关性/过度拟合",
          "reasoning": "解释为什么利用该特征作为判定依据是不可靠的。"
        }}
      ]
    }}
    """

    # 2. 构建包含图像序列的输入
    c2 = [{"type": "text", "text": prompt2}]

    # 辅助说明，确保模型明确图像的标签身份
    c2.append({"type": "text", "text": "=== 待审计的【训练集正例】 (Target Category Samples) ==="})
    for img_data in train_pos:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    c2.append({"type": "text", "text": "=== 待审计的【训练集负例】 (Negative Samples) ==="})
    for img_data in train_neg:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    # 3. 执行 API 调用
    r2_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c2}], 
        response_format={"type": "json_object"}
    )

    r2_content = r2_res.choices[0].message.content

    # --- 阶段 3: Agent 3 (合成最终规则) ---
    print("⚖️ 阶段 3: Agent 3 合成最终规则...")
    prompt3 = f"""
    # ROLE
    - 你是一位行业标准首席架构师
    - 你需要判断挑战意见的合理性，并再次对照原始图片，优化和调整初步规则，形成最终的行业判别准则。
    # Definition：
    - **初步规则**：由一位行业逻辑架构师对比正负样本，发现的判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    - **挑战意见**：由一位审计人员对比正负样本和**初步规则**提出的挑战性建议。
    - **逻辑一致性**：规则不应存在内部矛盾
    - **有效性**：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - **伪相关性**：规则不应包含与{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
    - **过度拟合**：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    
    # INPUT_INITIAL: {r1_content}
    # INPUT_CHALLENGES: {r2_content}
    
    # WORKFLOW: 
    ## Step 1: 综合理解
    - 对照【训练集正例】与【训练集负例】图片，全面理解阅读**初步规则 (INPUT_INITIAL)**、**挑战意见 (INPUT_CHALLENGES)**。
    ## Step 2: **挑战意见**审核
    - 从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度，理性判断**挑战意见**的合理性
    - 仅保留“挑战意见”中合理的部分。
    ## Step 3: **行业判别标准**生成
    - 结合**挑战意见**中合理的部分，优化**初步规则**，形成**行业判别标准**。
    ## Step 4: 双重校验
    - 再次基于【训练集正例】与【训练集负例】图片，从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度评价**行业判别标准**。若符合标准则输出；若不符合标准则继续优化。
    
    # CONSTRAITS:
    - 严禁盲信**挑战意见**的观点，你是老板，你优最终选择权。
    - **重要指示**：你所提炼的规则既要尽可能召回所有的正例，又要尽可能避免错召不符合条件的案例。换言之，你需要维护精确率和召回率的平衡。
   

    # OUTPUT STANDARD: 以JSON 格式输出 final_rules 数组，结构如下：
    {{
      "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
      "visual_cues": [
        {{
          "cue_id": "C1",
          "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
        }}
      ],
      "decision_rules": [
        {{
          "rule_id": "R1",
          "logic": "C1 AND C2",
          "target": "POSITIVE"
        }},
        {{
          "rule_id": "R2",
          "logic": "C3 AND (NOT C4)",
          "target": "POSITIVE"
        }}
      ]
    }}
        """

    # 构建包含图片的输入
    c3 = [{"type": "text", "text": prompt3}, {"type": "text", "text": "=== 参照对比：训练集正例 ==="}]
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c3.append({"type": "text", "text": "=== 参照对比：训练集负例 ==="})
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])

    r3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c3}], 
        response_format={"type": "json_object"}
    )
    r3_content = r3_res.choices[0].message.content

# ... (后续阶段 4 和结果汇总代码保持不变)

    # --- 阶段 4: Agent 4 评估 ---
    print("📊 阶段 4: Agent 4 进行审计与效能实测...")
    
    # 定义结构化 Prompt，明确 Key 的名称以防解析失败
    score_p_template = """
    # ROLE: 规则质量评估专家
    # WORKFLOW: 
    请对以下规则进行四个维度的量化打分（每个维度满分 25 分，总分 100 分）：
    1. 逻辑一致性：规则内部是否存在矛盾。
    2. 业务相关性：是否有效剔除了与主题无关的噪音（如背景、无关杂物）。
    3. 完备性：规则是否覆盖了区分正负样本的核心视觉信号。
    4. 可操作性：规则描述是否清晰，能否被第三方准确执行。
    
    # INPUT: 
    {rules_to_score}
    
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，不得包含解释文字。必须包含 "scores" 字典，其 Key 必须严格为: 
    "logic", "relevance", "completeness", "operability"。此外包含 "total_score"。
    """

    # 判定并生成初始规则评分 (使用 f-string 避免 .format 错误)
    s1_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r1_content)}"}], 
        response_format={"type":"json_object"}
    )
    s1_json = s1_res.choices[0].message.content
    
    # 判定并生成最终规则评分
    s3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r3_content)}"}], 
        response_format={"type":"json_object"}
    )
    s3_json = s3_res.choices[0].message.content

    # 解析数据 (确保你的 parse_score_json 函数能处理 logic, relevance 等 Key)
    s1_data = parse_score_json(s1_json)
    s3_data = parse_score_json(s3_json)
    
    # 效能实测 (仅基于测试集)
    r1_p, r1_r = perform_test(r1_content, test_pos, test_neg)
    r3_p, r3_r = perform_test(r3_content, test_pos, test_neg)

    # ==========================================
    # 5. 结果汇总输出
    # ==========================================
    print("\n" + "★"*40)
    print("【1. 智能体 1：初始规则内容】")
    print(r1_content)
    print("\n【2. 智能体 2：挑战意见】")
    print(r2_content)
    print("\n【3. 智能体 3：最终合成规则内容】")
    print(r3_content)
    
    print("\n【4. 综合进化对比表 (指标基于测试集)】")
    print("-" * 95)
    print(f"{'评估维度':<16} | {'零启动(Zero-Shot)':<18} | {'初始规则(Initial)':<18} | {'最终规则(Final)':<18}")
    print("-" * 95)
    
    rows = [("逻辑一致性","logic"), ("业务相关性","relevance"), ("完备性","completeness"), ("可操作性","operability"), ("内容总分","total")]
    for name, key in rows:
        v1, v3 = s1_data[key], s3_data[key]
        print(f"{name:<16} | {'--':<18} | {v1:<18} | {v3:<18}")
    
    print("-" * 95)
    print(f"{'精确率 (Prec.)':<16} | {zs_p:<18.2%} | {r1_p:<18.2%} | {r3_p:<18.2%}")
    print(f"{'召回率 (Rec.)':<16} | {zs_r:<18.2%} | {r1_r:<18.2%} | {r3_r:<18.2%}")
    print("-" * 95)
 
run_workflow()
```

![截屏2026-01-21 02.19.32.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/4042e9dd-d015-4ca1-9e86-7273a9c85115.png)

# 0114-119

1.  完成完成简易版简易版kgrag知识图谱建立与rag检索增强的代码。结合lixiao提供的论文进行尝试，并用张雨萌的模拟信息尝试分析。
    
    ```plaintext
    
    # ==========================================
    # 1. 基础配置 (请填入你的信息)
    # ==========================================
    os.environ["OPENAI_API_KEY"] = "sk-EIB06AaO2RkB2hKAHpb6cgn1neIAERjVz5vawh2T6TDGUCz2"
    os.environ["OPENAI_BASE_URL"] = "https://www.dmxapi.cn/v1" # 例如 https://api.openai-sb.com/v1
    
    # 初始化模型
    embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
    llm = ChatOpenAI(model="qwen3-max", temperature=0.1)
    
    # ==========================================
    # 2. 语义分块 (Semantic Chunking)
    # ==========================================
    pdf_name = "xinlixue1.pdf"
    
    def get_semantic_chunks(file_path):
        if not os.path.exists(file_path):
            # 如果文件不存在，自动生成一段心理学测试文本，防止代码报错
            print(f"警告：未找到 {file_path}，已生成模拟心理学数据...")
            text = "小太阳在社交场合表现出强烈的回避行为，这可能源于其童年时期的不安全依恋模式。认知行为疗法（CBT）被提议作为干预手段，旨在挑战其核心信念。此外，由于长期的情绪压抑，小太阳还伴有躯体化症状，如心悸和失眠。"
        else:
            reader = PdfReader(file_path)
            text = "".join([page.extract_text() for page in reader.pages])
        
        # 真正的语义分块：基于嵌入向量的相似度阈值切分
        semantic_splitter = SemanticChunker(embeddings, breakpoint_threshold_type="percentile")
        docs = semantic_splitter.create_documents([text])
        return [doc.page_content for doc in docs]
    
    print("正在执行心理学语义分块...")
    chunks = get_semantic_chunks(pdf_name)
    
    # ==========================================
    # 3. 图构建与多级聚类标签
    # ==========================================
    
    # 提取底层 Meta-MedGraph
    graph_prompt = ChatPromptTemplate.from_template("""
    你是一个资深心理学专家。请处理以下文本块：
    1. 提取实体（情感、行为表现、心理机制、治疗手段）。
    2. 提取它们的关系。
    3. 生成3个用于聚类分析的心理学关键词标签。
    
    输出 JSON 格式（不要包含 markdown 代码块标签）：
    {{
      "entities": [{{"id": "E1", "name": "名称", "type": "类型", "context": "描述"}}],
      "relations": [{{"source": "E1", "target": "E2", "relation": "描述"}}],
      "tags": ["标签1", "标签2", "标签3"]
    }}
    文本内容：{text}
    """)
    
    meta_graphs = []
    print("正在构建底层 Meta-MedGraph 知识点...")
    for i, chunk in enumerate(chunks):
        res = (graph_prompt | llm).invoke({"text": chunk})
        try:
            # 清洗 LLM 可能输出的 markdown 格式
            json_str = res.content.strip().replace("```json", "").replace("```", "")
            data = json.loads(json_str)
            data['chunk_id'] = f"G_bottom_{i}"
            data['content'] = chunk
            meta_graphs.append(data)
        except: continue
    
    # --- 核心：多层级聚类逻辑 ---
    def build_higher_layers(nodes, layer_prefix):
        """通过凝聚聚类构建更高层级的摘要标签"""
        if len(nodes) < 2: return nodes
        
        # 获取标签向量并聚类
        vecs = embeddings.embed_documents([" ".join(n.get('tags', [n.get('tag', '')])) for n in nodes])
        n_clusters = max(1, len(nodes) // 2)
        clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='cosine', linkage='average')
        cluster_labels = clustering.fit_predict(vecs)
        
        higher_nodes = []
        for cid in range(n_clusters):
            indices = np.where(cluster_labels == cid)[0]
            members = [nodes[i] for i in indices]
            
            # 让 LLM 生成高层摘要
            all_tags = [m.get('tags', [m.get('tag', '')]) for m in members]
            summary_query = f"以下是几组心理学标签：{all_tags}。请给它们起一个高层分类名（tag）并写一句总结（summary）。格式：{{'tag': '...', 'summary': '...'}}"
            s_res = llm.invoke(summary_query).content.strip().replace("'", "\"")
            try:
                s_data = json.loads(s_res)
                higher_nodes.append({
                    "id": f"Node_{layer_prefix}_{cid}",
                    "tag": s_data['tag'],
                    "summary": s_data['summary'],
                    "children": [m.get('chunk_id') or m.get('id') for m in members]
                })
            except: continue
        return higher_nodes
    
    print("正在构建中层摘要 (Layer 1)...")
    layer_1 = build_higher_layers(meta_graphs, "L1")
    print("正在构建顶层分类 (Layer 2)...")
    layer_2 = build_higher_layers(layer_1, "L2")
    
    # ==========================================
    # 4. U-Retrieval 互动引擎 (下行定位 + 上行精炼)
    # ==========================================
    
    def u_retrieval_answer(query):
        # 1. Top-down: 逐级向下定位最相关的图
        print(f"📍 [下行] 定位最相关的心理学范畴...")
        q_vec = embeddings.embed_query(query)
        
        def get_best_match(candidates, query_vec):
            scores = [np.dot(query_vec, embeddings.embed_query(c.get('tag', ' '.join(c.get('tags', []))))) for c in candidates]
            return candidates[np.argmax(scores)]
    
        best_l2 = get_best_match(layer_2, q_vec)
        l1_candidates = [n for n in layer_1 if n['id'] in best_l2['children']]
        best_l1 = get_best_match(l1_candidates, q_vec)
        
        # 找到最终的底层知识块
        target_graphs = [g for g in meta_graphs if g['chunk_id'] in best_l1['children']]
        
        # 2. Bottom-up: 自底向上精炼 (Refinement)
        print(f"✨ [上行] 结合证据链生成回答...")
        
        # 初稿：基于最细碎的图实体关系
        context_str = json.dumps(target_graphs, ensure_ascii=False)
        draft = llm.invoke(f"基于以下证据回复问题 '{query}': {context_str}").content
        
        # 精炼：结合中层摘要进行修正
        refine_1 = llm.invoke(f"基于中层背景 '{best_l1['summary']}' 修正以下回复：{draft}").content
        
        # 终稿：基于顶层范畴进行专业校准
        final = llm.invoke(f"基于总体分类 '{best_l2['tag']}'，对该回复进行专业术语优化：{refine_1}").content
        
        return final, target_graphs
    
    # ==========================================
    # 5. 交互界面
    # ==========================================
    
    def launch_ui():
        input_box = widgets.Text(placeholder='输入关于“小太阳”心理状态的问题...', layout={'width': '70%'})
        search_btn = widgets.Button(description="MedGraphRAG 检索", button_style='success')
        out_box = widgets.Output()
    
        def on_click(b):
            with out_box:
                out_box.clear_output()
                if not input_box.value: return
                ans, retrieved_nodes = u_retrieval_answer(input_box.value)
                display(HTML(f"<b>【专家解析】</b><br><div style='background:#f9f9f9; padding:15px; border-left:5px solid #28a745;'>{ans}</div>"))
                
                # 展示本次检索涉及到的关系图
                G_vis = nx.DiGraph()
                for g in retrieved_nodes:
                    for ent in g['entities']:
                        G_vis.add_node(ent['name'], title=ent['context'], color='#ffcc00')
                    for rel in g['relations']:
                        G_vis.add_edge(rel['source'], rel['target'], label=rel['relation'])
                
                net = Network(notebook=True, height="400px", width="100%", directed=True)
                net.from_nx(G_vis)
                display(HTML("<br><b>涉及的底层心理图谱：</b>"))
                display(net.show("result_graph.html"))
    
        search_btn.on_click(on_click)
        display(HTML("<h2>《小太阳》心理疾病深度 RAG 互动系统</h2>"))
        display(input_box, search_btn, out_box)
    
    launch_ui()
    ```
    
    同时通过可视化代码要求可视化知识图谱。
    
    ```plaintext
    import networkx as nx
    from pyvis.network import Network
    from IPython.display import IFrame
    
    def visualize_full_hierarchy(l2_nodes, l1_nodes, bottom_graphs):
        # 1. 创建一个有向图对象
        G = nx.DiGraph()
    
        # 配置颜色和尺寸方案
        COLOR_L2 = "#FF4B4B"  # 红色：顶层
        COLOR_L1 = "#1C64F2"  # 蓝色：中层
        COLOR_CHUNK = "#31C48D" # 绿色：底层块
        COLOR_ENTITY = "#FACA15" # 黄色：具体实体
        
        # 2. 添加顶层节点 (Layer 2)
        for node in l2_nodes:
            G.add_node(node['id'], label=node['tag'], title=f"顶层摘要: {node['summary']}", color=COLOR_L2, size=40, shape="diamond")
            
            # 3. 添加中层节点 (Layer 1) 并建立连接
            for l1 in l1_nodes:
                if l1['id'] in node['children']:
                    G.add_node(l1['id'], label=l1['tag'], title=f"中层摘要: {l1['summary']}", color=COLOR_L1, size=30, shape="dot")
                    G.add_edge(node['id'], l1['id'], label="包含")
                    
                    # 4. 添加底层块 (Meta-MedGraph) 并建立连接
                    for chunk in bottom_graphs:
                        if chunk['chunk_id'] in l1['children']:
                            G.add_node(chunk['chunk_id'], label="数据块", title=f"原文片段: {chunk['content'][:100]}...", color=COLOR_CHUNK, size=20, shape="box")
                            G.add_edge(l1['id'], chunk['chunk_id'], label="索引自")
                            
                            # 5. 添加具体的实体和它们之间的关系
                            for ent in chunk['entities']:
                                # 实体节点
                                G.add_node(ent['name'], label=ent['name'], title=f"类型: {ent['type']}\n定义: {ent['context']}", color=COLOR_ENTITY, size=15)
                                G.add_edge(chunk['chunk_id'], ent['name'], label="提取出")
                                
                            for rel in chunk['relations']:
                                # 实体间的语义关系
                                G.add_edge(rel['source'], rel['target'], label=rel['relation'], color="#999999", arrows="to")
    
        # 6. 使用 pyvis 进行渲染
        net = Network(notebook=True, height="750px", width="100%", directed=True, heading="MedGraphRAG 心理学全层级索引图谱")
        
        # 物理引擎设置：让图表自动排布得更好看
        net.from_nx(G)
        net.set_options("""
        var options = {
          "physics": {
            "forceAtlas2Based": { "gravitationalConstant": -50, "centralGravity": 0.01, "springLength": 100 },
            "solver": "forceAtlas2Based",
            "stabilization": { "iterations": 150 }
          }
        }
        """)
        
        # 保存并显示
        file_name = "full_medgraph_hierarchy.html"
        net.show(file_name)
        return file_name
    
    # 执行可视化
    graph_file = visualize_full_hierarchy(layer_2, layer_1, meta_graphs)
    
    # 强制在 Jupyter 中以 IFrame 形式展示
    print(f"图谱已生成。如果下方没有自动显示，请手动打开目录下的 {graph_file}")
    display(IFrame(src=graph_file, width='100%', height='800px'))
    ```
    
    但通过效果图可以发现，知识图谱提取的实体和关系并不清晰。其根本原因在schema定义不清
    
2.  完成从论文提取知识图谱+kgrag检索增强全链路的梳理。撰写了用来vibe coding的提示词，并根据论文内容调整了每一个分任务中需要用到的提示词。
    

```plaintext
# role and background
- 你一名熟悉 nano-graphrag、Neo4j、异步 LLM 管道与知识图谱工程的高级 Python 工程师
- 我希望你帮我撰写一个knowledgegraphrag的代码。不仅需要包括知识图谱的生成，更需要运用这个知识图谱帮助我完成相关的生成工作。


# workflow of the code
以下是我希望你的代码需要实现的所有基本功能，我希望你能严格执行
## Part 1：知识图谱的搭建
- 你的主要任务是根据拿到的若干文本，提炼可用的知识图谱。
- 你需要一篇文章一篇文章进行处理，但允许异步处理。即文章a在进行图谱生成环节时，文章b可以进行文本的预处理工作
### Step 1: 文本输入与基础处理
- 1. 你会拿到若干篇论文或者文献。文本的格式可能是pdf或者txt等各种情况。你需要提炼其所有的文本
- 2. 执行【物理分段】，利用两个换行符作为分隔标识，将整篇长文章切成多个自然段。
### Step 2: chunk建立
- 对于每一篇文章，我们都希望根据文本的语义建立各种不同的chunk。请对step1输出的每一个自然段，依次进行如下操作
- 1.自然段proposition拆分：运用wfh/proposal-indexing prompt对每一个自然段进行具体proposition的拆分
- 2.将每一个propositon放入合适的chunk中
    - （1）如果当前尚未建立一个chunk，则针对该条proposition之间建立一个chunk,赋予chunk_id。并且运用"chunk_title_prompt"和"chunk_abstract_prompt"为该chunk建立chunk_title和chunk_abstract。
    - （2）如果当前已有chunk，则进行如下步骤。
        - A.运用"find_relevant_chunk_prompt"将proposition与chunk_outline进行匹配，找出最合适的chunk，并返回chunk_id
        - B.运用"chunk_title_renew_prompt"和“chunk_title_renew_prompt"，结合对应chunk_id原本的chunk_title, chunk_abstract, 新添加的propostion，撰写并存储新的chunk_title和chunk_abstract。
    - （3）为了便利每一次chunk查询任务，我需要建立chunk_outline。他的本质是一个呈现当前文章中所有chunk_abstract和chunk_title的工具。每一个数据都需要包括{chunk_id, chunk_title, chunk_abstract}
- 3.根据每一chunk中的proposition写一个summary，并与对应的chunk_id绑定。当chunk中出现新的propostion之后，需要根据“summary_prompt"重写summary。
### Step 3: 知识图谱搭建
- 1.对每一个chunk中的proposition以字符串的形式进行输出。随后根据提取entity和relation
    -（1）entitiy的提取需要包括以下内容：
        - entity_name：实体名称（标准化、去别名）
        - entity_type：
            - entity_types = [
            "Disease", "Symptom", "Treatment", "Medication", "Test", 
            "Anatomy", "Procedure", "Condition", "Measurement", "Hormone",
            "Diagnostic_Criteria", "Clinical_Guideline", "Patient", "Doctor"]
        - entity_description：该实体在当前 chunk / proposition 语境下的功能性描述
    -（2）relation 的提取需要包括以下内容：
        - source_entity
        - target_entity
        - relation_type：包括"TREATS", "CAUSES", "INDICATES", "HAS_SYMPTOM"四类
        - relation_description：对关系成立原因的解释
- 2.将每一个chunk中的entity和relation写进neoj4数据库，每一个chunk的meta_graph中的所有节点和关系都赋予相同的gid和chunk_id
- 3.节点融合：运用余弦向量计算entity之间的相似性，当大于等于0.6时，可以进行节点融合。节点融合后，以新图的chunkid和gid命名该节点。
- 4.设立summary节点。运用"summary_prompt"对本篇文献进行summarize，并写进这个节点。
### Step 4: KnowldgeGraph Rag
- 1.用户query改写：运用"summary_prompt"对用户的query进行改写。
- 2.基于“rating_prompt"对用户query和每一张图的summary进行打分。
- 3.赋予'very similar'4分, 'similar'3分, 'general'2分，'not similar'1分，'totally not similar'0分。
- 4.根据分数进行排序，返回分数最高的一张图的gid
- 5.进一步匹配相同gid下，不同chunk_id的summry，并进行打分。
- 6.返回所有得分为3分的chunk_id
- 7.基于所有的chunk_id，返回对应的图以及图相关节点向外延伸的单跳节点与关系。
- 8.将图里的信息压缩为文字
- 9.结合"new_query_prompt",引导模型结合补充信息回答用户的query。

# output
- 我希望你搭建一个demo，让我可以上传论文，并进行交互
- 需要支持多篇论文同时输入
- 需要支持对生成的知识图谱进行可视化
- 如果无法通过上述方法清晰识别每一个自然段，你可以选择采取其他方法。

#prompt base
- "new_query_prompt"="""
  You are given information retrieved by a Knowledge Graph–enhanced RAG (KGRAG) system.
  Use only the retrieved information to answer the user’s query.
  
  Integrate facts across entities and relations when relevant.
  
  If the retrieved information is insufficient, clearly state that the answer cannot be determined from the given context.
  
  Do not introduce external knowledge or assumptions.
"""
- "find_relevant_chunk_prompt"="""
    Determine whether or not the "Proposition" should belong to any of the existing chunks.
    
                    A proposition should belong to a chunk of their meaning, direction, or intention are similar.
                    The goal is to group similar propositions and chunks.
    
                    If you think a proposition should be joined with a chunk, return the chunk id.
                    If you do not think an item should be joined with an existing chunk, just return "No chunks"
    
                    Example:
                    Input:
                        - Proposition: "Greg really likes hamburgers"
                        - Current Chunks:
                            - Chunk ID: 2n4l3d
                            - Chunk title: Places in San Francisco
                            - Chunk Abstract: Overview of the things to do with San Francisco Places
    
                            - Chunk ID: 93833k
                            - Chunk title: Food Greg likes
                            - Chunk abstract: Lists of the food and dishes that Greg likes
                    Output: 93833k
- "chunk_title_renew_prompt"="""
    You are the steward of a group of chunks which represent groups of sentences that talk about a similar topic
    A new proposition was just added to one of your chunks, you should generate a very brief updated chunk title which will inform viewers what a chunk group is about.
    A good title will say what the chunk is about.
    You will be given a group of propositions which are in the chunk, chunk abstract and the chunk title.
    Your title should anticipate generalization. If you get a proposition about apples, generalize it to food.
    Or month, generalize it to "date and times".
    
    Example:
    Input: abstract: This chunk is about dates and times that the author talks about
    Output: Date & Times

    Only respond with the new chunk title, nothing else.
    """
    
-"chunk_abstract_renew_prompt"="""
        You are the steward of a group of chunks which represent groups of sentences that talk about a similar topic
        A new proposition was just added to one of your chunks, you should generate a very brief 1-sentence abstract which will inform viewers what a chunk group is about.

        A good abstract will say what the chunk is about, and give any clarifying instructions on what to add to the chunk.

        You will be given a group of propositions which are in the chunk and the chunks current abstract.

        Your abstracts should anticipate generalization. If you get a proposition about apples, generalize it to food.
        Or month, generalize it to "date and times".

        Example:
        Input: Proposition: Greg likes to eat pizza
        Output: This chunk contains information about the types of food Greg likes to eat.

        Only respond with the chunk new abstract, nothing else.
        """

- “chunk_title_prompt"="""
    You are the stewad of a group of chunks which represent groups of sentences that talk about a similar topic
    You should generate a very brief few word chunk title which will inform viewers what a chunk group is about.
    A good chunk title is brief but encompasses what the chunk is about
    You will be given an abstract of a chunk which needs a title
    Your titles should anticipate generalization. If you get a proposition about apples, generalize it to food.
    Or month, generalize it to "date and times".
    
    Example:
    Input: abstract: This chunk is about dates and times that the author talks about
    Output: Date & Times

    Only respond with the new chunk title, nothing else.
    """

- "chunk_abstract_prompt"="""
    You are the steward of a group of chunks which represent groups of sentences that talk about a similar topic
    You should generate a very brief 1-sentence summary which will inform viewers what a chunk group is about.
    A good summary will say what the chunk is about, and give any clarifying instructions on what to add to the chunk.
    You will be given a proposition which will go into a new chunk. This new chunk needs an abstract.
    Your abstracts should anticipate generalization. If you get a proposition about apples, generalize it to food.
    Or month, generalize it to "date and times".

    Example:
    Input: Proposition: Greg likes to eat pizza
    Output: This chunk contains information about the types of food Greg likes to eat.

    Only respond with the new chunk abstract, nothing else.
    """
- "wfh/proposal-indexing prompt"="""
    Decompose the "Content" into clear and simple propositions, ensuring they are interpretable out of
    context.
    1. Split compound sentence into simple sentences. Maintain the original phrasing from the input
    whenever possible.
    2. For any named entity that is accompanied by additional descriptive information, separate this
    information into its own distinct proposition.
    3. Decontextualize the proposition by adding necessary modifier to nouns or entire sentences
    and replacing pronouns (e.g., "it", "he", "she", "they", "this", "that") with the full name of the
    entities they refer to.
    4. Present the results as a list of strings, formatted in JSON.
    
    Example:
    
    Input: Title: ¯Eostre. Section: Theories and interpretations, Connection to Easter Hares. Content:
    The earliest evidence for the Easter Hare (Osterhase) was recorded in south-west Germany in
    1678 by the professor of medicine Georg Franck von Franckenau, but it remained unknown in
    other parts of Germany until the 18th century. Scholar Richard Sermon writes that "hares were
    frequently seen in gardens in spring, and thus may have served as a convenient explanation for the
    origin of the colored eggs hidden there for children. Alternatively, there is a European tradition
    that hares laid eggs, since a hare’s scratch or form and a lapwing’s nest look very similar, and
    both occur on grassland and are first seen in the spring. In the nineteenth century the influence
    of Easter cards, toys, and books was to make the Easter Hare/Rabbit popular throughout Europe.
    German immigrants then exported the custom to Britain and America where it evolved into the
    Easter Bunny."
    Output: [ "The earliest evidence for the Easter Hare was recorded in south-west Germany in
    1678 by Georg Franck von Franckenau.", "Georg Franck von Franckenau was a professor of
    medicine.", "The evidence for the Easter Hare remained unknown in other parts of Germany until
    the 18th century.", "Richard Sermon was a scholar.", "Richard Sermon writes a hypothesis about
    the possible explanation for the connection between hares and the tradition during Easter", "Hares
    were frequently seen in gardens in spring.", "Hares may have served as a convenient explanation
    for the origin of the colored eggs hidden in gardens for children.", "There is a European tradition
    that hares laid eggs.", "A hare’s scratch or form and a lapwing’s nest look very similar.", "Both
    hares and lapwing’s nests occur on grassland and are first seen in the spring.", "In the nineteenth
    century the influence of Easter cards, toys, and books was to make the Easter Hare/Rabbit popular
    throughout Europe.", "German immigrants exported the custom of the Easter Hare/Rabbit to
    Britain and America.", "The custom of the Easter Hare/Rabbit evolved into the Easter Bunny in
    Britain and America."]
    """
- "summary_prompt" = """
        Generate a structured summary from the provided medical source (report, paper, or book), strictly adhering to the following categories. The summary should list key information under each category in a concise format: 'CATEGORY_NAME: Key information'. No additional explanations or detailed descriptions are necessary unless directly related to the categories:
        
        ANATOMICAL_STRUCTURE: Mention any anatomical structures specifically discussed.
        BODY_FUNCTION: List any body functions highlighted.
        BODY_MEASUREMENT: Include normal measurements like blood pressure or temperature.
        BM_RESULT: Results of these measurements.
        BM_UNIT: Units for each measurement.
        BM_VALUE: Values of these measurements.
        LABORATORY_DATA: Outline any laboratory tests mentioned.
        LAB_RESULT: Outcomes of these tests (e.g., 'increased', 'decreased').
        LAB_VALUE: Specific values from the tests.
        LAB_UNIT: Units of measurement for these values.
        MEDICINE: Name medications discussed.
        MED_DOSE, MED_DURATION, MED_FORM, MED_FREQUENCY, MED_ROUTE, MED_STATUS, MED_STRENGTH, MED_UNIT, MED_TOTALDOSE: Provide concise details for each medication attribute.
        PROBLEM: Identify any medical conditions or findings.
        PROCEDURE: Describe any procedures.
        PROCEDURE_RESULT: Outcomes of these procedures.
        PROC_METHOD: Methods used.
        SEVERITY: Severity of the conditions mentioned.
        MEDICAL_DEVICE: List any medical devices used.
        SUBSTANCE_ABUSE: Note any substance abuse mentioned.
        Each category should be addressed only if relevant to the content of the medical source. Ensure the summary is clear and direct, suitable for quick reference.
        """
 - "rating_prompt"="""
        Assess the similarity of the two provided summaries and return a rating from these options: 'very similar', 'similar', 'general', 'not similar', 'totally not similar'. Provide only the rating.
        """
```

# 0112-0113

1.  开始尝试不告诉模型看到的图片是憎恶，但准召率开始明显下降。因为告诉了模型CONFIG\['INDUSTRY\_TOPIC'\]之后可能可以更好地结合模型已有得知识。此处prompt需要 $\color{#0089FF}{@刘远歌}$ 进一步优化
    

```plaintext


# ==========================================
# 1. 配置中心
# ==========================================
CONFIG = {
    "API_KEY": "sk-EIB06AaO2RkB2hKAHpb6cgn1neIAERjVz5vawh2T6TDGUCz2", 
    "BASE_URL": "https://www.dmxapi.cn/v1", 
    "INDUSTRY_TOPIC": "憎恶的表情图片", 
    "PATHS": {
        "TRAIN_POS": "./训练集憎恶正例",
        "TRAIN_NEG": "./训练集憎恶负例",
        "TEST_POS": "./测试集憎恶正例",
        "TEST_NEG": "./测试集憎恶负例",
    },
    "MODEL": "Qwen3-VL-235B-A22B-Instruct" 
}

# 初始化客户端
client = OpenAI(api_key=CONFIG["API_KEY"].strip(), base_url=CONFIG["BASE_URL"].strip())

# ==========================================
# 2. 工具函数
# ==========================================
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def load_images_safe(folder_path, label):
    """安全读取图片并返回base64列表"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        print(f"⚠️ 文件夹已创建但目前为空: {folder_path}，请放入{label}图片后重新运行。")
        return []
    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    print(f"📂 已加载 {label}: {len(files)} 张图片")
    # 限制训练集读取张数防止Token溢出，测试集不限
    limit = 8 if "训练" in label else 100
    return [encode_image(os.path.join(folder_path, f)) for f in files[:limit]]

def parse_score_json(json_str):
    """鲁棒的JSON解析，兼容中英文键名"""
    try:
        d = json.loads(json_str)
        scores_part = d.get("scores", d)
        def find_s(keys):
            for k, v in scores_part.items():
                if any(ik in k.lower() for ik in keys): return v
            return 0
        return {
            "logic": find_s(["logic", "逻辑"]),
            "relevance": find_s(["relevance", "相关", "业务"]),
            "completeness": find_s(["completeness", "完备", "覆盖"]),
            "operability": find_s(["operability", "操作", "执行"]),
            "total": d.get("total_score", d.get("总分", 0))
        }
    except:
        return {"logic":0, "relevance":0, "completeness":0, "operability":0, "total":0}

# ==========================================
# 3. 核心判定逻辑 (Agent 0, 4)
# ==========================================
def perform_test(rules_text, pos_list, neg_list, is_zero_shot=False):
    """在测试集上运行P/R测试"""
    tp, fp, tn, fn = 0, 0, 0, 0
    if is_zero_shot:
        prompt = f"# ROLE: 通用视觉判定专家\n# CONTEXT: 仅凭常识判定图片是否符合主题：{CONFIG['INDUSTRY_TOPIC']}。\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"
    else:
        prompt = f"# ROLE: 你是一个规则执行官，你首先需要依照{rules_text}判断图片是否符合该规则；随后再进行一次检查，然后再给出最终答案。\n# RULE: {rules_text}\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"

    for img in pos_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): tp += 1
        else: fn += 1
    for img in neg_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): fp += 1
        else: tn += 1
    
    p = tp/(tp+fp) if (tp+fp)>0 else 0
    r = tp/(tp+fn) if (tp+fn)>0 else 0
    return p, r

# ==========================================
# 4. 主工作流
# ==========================================
def run_workflow():
    # A. 数据加载
    print("🎬 正在初始化数据...")
    train_pos = load_images_safe(CONFIG["PATHS"]["TRAIN_POS"], "训练集正例")
    train_neg = load_images_safe(CONFIG["PATHS"]["TRAIN_NEG"], "训练集负例")
    test_pos = load_images_safe(CONFIG["PATHS"]["TEST_POS"], "测试集正例")
    test_neg = load_images_safe(CONFIG["PATHS"]["TEST_NEG"], "测试集负例")

    if not train_pos or not train_neg or not test_pos or not test_neg:
        print("🛑 错误：文件夹图片不足，请准备好图片后再运行。")
        return

    # --- 阶段 0: 零启动测试 ---
    print("🔍 阶段 0: 零启动测试（基于测试集）...")
    zs_p, zs_r = perform_test(None, test_pos, test_neg, is_zero_shot=True)

    # --- 阶段 1: Agent 1 (初始规则) ---
    print("🤖 阶段 1: Agent 1 提炼初始规则...")
    prompt1 = f"""
    # ROLE
    - 你是一名资深的【计算机视觉特征工程专家】与【行业逻辑架构师】。
    - 你的任务是：基于正负样本对比，发现判断正例所需的**最小充分视觉规则**。

    # LOGIC PHILOSOPHY
    - **保留潜在元素**：即使某个特征在负样本中也存在，只要它可能是构成判定组合的一部分，就必须保留。
    - **证伪驱动修正**：将正样本中提取的“初版规则”放在负样本中运行，若误判，则通过增加约束条件（AND/NOT）来修正，而非直接删除特征。
    - **最小化路径**：在确保 100% 区分正负样本的前提下，规则描述应尽可能简洁。
    - **视觉元素**：包括且仅包括动作和表情。

    # INPUT
    - **Positive Samples**: 符合正例标准的图片集。
    - **Negative Samples**: 不符合标准的干扰项图片集。

    ---

    # EXPLICIT WORKFLOW

    ## STEP 1：正样本特征提取与规则初探 (Hypothesis Generation)
    - **视觉原点挖掘**：观察所有正样本，提取出所有显著的视觉元素（特征 A, B, C...）。
    - **内部共性组合**：分析这些特征如何组合（单点或多点组合）能覆盖 100% 的正样本。
    - **建立初版规则**：例如：“规则1 = A + B” 或 “规则2 = C”。

    ## STEP 2：负样本冲突测试 (Stress Testing & Conflict Detection)
    - **规则代入**：将 STEP 1 建立的初版规则逐一在负样本中测试。
    - **冲突记录**：如果负样本也触发了某条规则（即出现了 False Positive），详细记录该负样本在对应特征上的细微差异。
    - **识别判别增量**：寻找能将“触发规则的负样本”排除掉的额外视觉特征 D（即：在正样本中 A+B 且具备 D 属性，而负样本只有 A+B 但不具备 D）。

    ## STEP 3：动态修正与逻辑收敛 (Rule Refinement)
    - **规则打补丁**：利用 STEP 2 发现的增量，对初版规则进行加固。
      - *修正前*：Rule = A + B
      - *修正后*：Rule = A + B + (具备 D 属性/排除 E 环境)
    - **结构压缩**：检查修正后的规则，如果多个规则可以合并，或者某个特征在加入新约束后变得冗余，则进行精简。

    ## STEP 4：生成最终判定矩阵 (Final Synthesis)
    - 整理出一组相互独立且互补的规则，每条规则都是一条从视觉证据到判定的完整路径。

    ---
    # CONSTRAITS:
    - 你只能从**视觉元素**，即动作和表情中提取规则，不应包含与正例本质无关的特征（如背景、画质、光线、是否静态、拍摄角度、人物身份、画面中出现的字符等）
    - 你必须输出规则，不得输出为空

    # OUTPUT FORMAT (STRICT JSON ONLY)

    ```json
{{
  "industry_topic": "规则",
  "visual_cues": [
    {{
      "cue_id": "C1",
      "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
    }}
  ],
  "decision_rules": [
    {{
      "rule_id": "R1",
      "logic": "C1 AND C2",
      "target": "POSITIVE"
    }},
    {{
      "rule_id": "R2",
      "logic": "C3 AND (NOT C4)",
      "target": "POSITIVE"
    }}
  ]
}}
        """
    c1 = [{"type": "text", "text": prompt1}, {"type": "text", "text": "=== 训练集正例 ==="}]
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c1.append({"type": "text", "text": "=== 训练集负例 ==="})
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])
    
    r1_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": c1}], response_format={"type": "json_object"})
    r1_content = r1_res.choices[0].message.content

    # --- 阶段 2: Agent 2 (挑战者) ---
    print("🕵️ 阶段 2: Agent 2 开始审计规则逻辑与伪相关性...")
    # 1. 优化后的通用 Prompt
    prompt2 = f"""
    # ROLE
    - 你是一个逻辑漏洞审计员 (红队成员)
    - 你需要审核**行业逻辑架构师**从图像集中提取的【分类规则】。你的目标是发现规则中的逻辑漏洞、过度拟合以及“伪相关性”（Spurious Correlations）。

    # DEFINITION 
    - 【训练集正例】：完全符合目标类别的标准样本。
    - 【训练集负例】：不符合目标类别的样本，必须被规则准确排除。
    - **行业逻辑架构师**：其任务是基于正负样本对比，发现判断正例所需的**最小充分视觉规则**。
    - **视觉元素**：包括且仅包括动作和表情。
    
    # INPUT_RULES: {r1_content}
    
    # WORKFLOW:
    ## Step 1: **对比观察**
    - 结合正例与负例图片，逐条审查 INPUT_RULES。
    
    ##Step 2: **多维度审计**：
    - 从以下维度评价INPUT_RULES，并针对存在问题的部分提出质疑和反驳
        - 逻辑一致性：规则不应存在内部矛盾
        - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
        - 伪相关性：规则只能包括**视觉元素**的内容，不应包含与正例本质无关的特征（如背景、画质、光线、是否静态、拍摄角度、人物身份、画面中出现的字符等）
        - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    # CONSTRAITS:
    - 你必须严格围绕INPUT_RULES和正负例图片进行分析
    - 严禁为了反驳而反驳，你的每一条反驳必须有理有据。
    

    # OUTPUT STANDARD:
    必须以 JSON 格式输出，包含 challenges 数组，结构如下：
    {{
      "challenges": [
        {{
          "target_rule": "被质疑的原始规则条目",
          "logic_error_type": "逻辑一致性 / 有效性/ 伪相关性/过度拟合",
          "reasoning": "解释为什么利用该特征作为判定依据是不可靠的。"
        }}
      ]
    }}
    """

    # 2. 构建包含图像序列的输入
    c2 = [{"type": "text", "text": prompt2}]

    # 辅助说明，确保模型明确图像的标签身份
    c2.append({"type": "text", "text": "=== 待审计的【训练集正例】 (Target Category Samples) ==="})
    for img_data in train_pos:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    c2.append({"type": "text", "text": "=== 待审计的【训练集负例】 (Negative Samples) ==="})
    for img_data in train_neg:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    # 3. 执行 API 调用
    r2_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c2}], 
        response_format={"type": "json_object"}
    )

    r2_content = r2_res.choices[0].message.content

    # --- 阶段 3: Agent 3 (合成最终规则) ---
    print("⚖️ 阶段 3: Agent 3 合成最终规则...")
    prompt3 = f"""
    # ROLE
    - 你是一位行业标准首席架构师
    - 你需要判断挑战意见的合理性，并再次对照原始图片，优化和调整初步规则，形成最终的行业判别准则。
    # Definition：
    - **初步规则**：由一位行业逻辑架构师对比正负样本，发现的判断正例所需的**最小充分视觉规则**。
    - **挑战意见**：由一位审计人员对比正负样本和**初步规则**提出的挑战性建议。
    - **逻辑一致性**：规则不应存在内部矛盾
    - **有效性**：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - **伪相关性**：规则只能包括**视觉元素**的内容，不应包含与正例本质无关的特征（如背景、画质、光线、是否静态、拍摄角度、人物身份、画面中出现的字符等）
    - **过度拟合**：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    
    # INPUT_INITIAL: {r1_content}
    # INPUT_CHALLENGES: {r2_content}
    
    # WORKFLOW: 
    ## Step 1: 综合理解
    - 对照【训练集正例】与【训练集负例】图片，全面理解阅读**初步规则 (INPUT_INITIAL)**、**挑战意见 (INPUT_CHALLENGES)**。
    ## Step 2: **挑战意见**审核
    - 从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度，理性判断**挑战意见**的合理性
    - 仅保留“挑战意见”中合理的部分。
    ## Step 3: **行业判别标准**生成
    - 结合**挑战意见**中合理的部分，优化**初步规则**，形成**行业判别标准**。
    ## Step 4: 双重校验
    - 再次基于【训练集正例】与【训练集负例】图片，从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度评价**行业判别标准**。若符合标准则输出；若不符合标准则继续优化。
    
    # CONSTRAITS:
    - 严禁盲信**挑战意见**的观点，你是老板，你优最终选择权。

    # OUTPUT STANDARD: 以JSON 格式输出 final_rules 数组，结构如下：
    {{
      "industry_topic": "正例",
      "visual_cues": [
        {{
          "cue_id": "C1",
          "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
        }}
      ],
      "decision_rules": [
        {{
          "rule_id": "R1",
          "logic": "C1 AND C2",
          "target": "POSITIVE"
        }},
        {{
          "rule_id": "R2",
          "logic": "C3 AND (NOT C4)",
          "target": "POSITIVE"
        }}
      ]
    }}
        """

    # 构建包含图片的输入
    c3 = [{"type": "text", "text": prompt3}, {"type": "text", "text": "=== 参照对比：训练集正例 ==="}]
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c3.append({"type": "text", "text": "=== 参照对比：训练集负例 ==="})
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])

    r3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c3}], 
        response_format={"type": "json_object"}
    )
    r3_content = r3_res.choices[0].message.content

# ... (后续阶段 4 和结果汇总代码保持不变)

    # --- 阶段 4: Agent 4 评估 ---
    print("📊 阶段 4: Agent 4 进行审计与效能实测...")
    
    # 定义结构化 Prompt，明确 Key 的名称以防解析失败
    score_p_template = """
    # ROLE: 规则质量评估专家
    # WORKFLOW: 
    请对以下规则进行四个维度的量化打分（每个维度满分 25 分，总分 100 分）：
    1. 逻辑一致性：规则内部是否存在矛盾。
    2. 业务相关性：是否有效剔除了与主题无关的噪音（如背景、无关杂物）。
    3. 完备性：规则是否覆盖了区分正负样本的核心视觉信号。
    4. 可操作性：规则描述是否清晰，能否被第三方准确执行。
    
    # INPUT: 
    {rules_to_score}
    
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，不得包含解释文字。必须包含 "scores" 字典，其 Key 必须严格为: 
    "logic", "relevance", "completeness", "operability"。此外包含 "total_score"。
    """

    # 判定并生成初始规则评分 (使用 f-string 避免 .format 错误)
    s1_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r1_content)}"}], 
        response_format={"type":"json_object"}
    )
    s1_json = s1_res.choices[0].message.content
    
    # 判定并生成最终规则评分
    s3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r3_content)}"}], 
        response_format={"type":"json_object"}
    )
    s3_json = s3_res.choices[0].message.content

    # 解析数据 (确保你的 parse_score_json 函数能处理 logic, relevance 等 Key)
    s1_data = parse_score_json(s1_json)
    s3_data = parse_score_json(s3_json)
    
    # 效能实测 (仅基于测试集)
    r1_p, r1_r = perform_test(r1_content, test_pos, test_neg)
    r3_p, r3_r = perform_test(r3_content, test_pos, test_neg)

    # ==========================================
    # 5. 结果汇总输出
    # ==========================================
    print("\n" + "★"*40)
    print("【1. 智能体 1：初始规则内容】")
    print(r1_content)
    print("\n【2. 智能体 2：挑战意见】")
    print(r2_content)
    print("\n【3. 智能体 3：最终合成规则内容】")
    print(r3_content)
    
    print("\n【4. 综合进化对比表 (指标基于测试集)】")
    print("-" * 95)
    print(f"{'评估维度':<16} | {'零启动(Zero-Shot)':<18} | {'初始规则(Initial)':<18} | {'最终规则(Final)':<18}")
    print("-" * 95)
    
    rows = [("逻辑一致性","logic"), ("业务相关性","relevance"), ("完备性","completeness"), ("可操作性","operability"), ("内容总分","total")]
    for name, key in rows:
        v1, v3 = s1_data[key], s3_data[key]
        print(f"{name:<16} | {'--':<18} | {v1:<18} | {v3:<18}")
    
    print("-" * 95)
    print(f"{'精确率 (Prec.)':<16} | {zs_p:<18.2%} | {r1_p:<18.2%} | {r3_p:<18.2%}")
    print(f"{'召回率 (Rec.)':<16} | {zs_r:<18.2%} | {r1_r:<18.2%} | {r3_r:<18.2%}")
    print("-" * 95)

run_workflow()
```

![截屏2026-01-14 00.12.17.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/84e4d858-6f21-490b-9e20-396f1ca4bbfd.png)

# 0107

让挑战者和规则总结者都能看到图片

![截屏2026-01-07 13.18.45.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/160cf66c-a013-49dd-ae31-a292f095a8c1.png)

优化了初识规则prompt后

```plaintext
prompt1 = f"""
    # ROLE
    你是一名【视觉规则归纳专家 + 行业质检标准制定者】。
    你的任务不是描述图片，而是从打标图片中**归纳可复用、可执行的视觉判断规则**。

    # TASK OBJECTIVE
    基于一组已标注图片：
    - 正样本（符合【{CONFIG['INDUSTRY_TOPIC']}】标准）
    - 负样本（不符合【{CONFIG['INDUSTRY_TOPIC']}】标准）
    总结出一套**仅依赖视觉信息**、可用于判断新图片是否符合【{CONFIG['INDUSTRY_TOPIC']}】的行业级规则。

    # INPUT
    - 正样本图片集（Positive Samples）：已确认“符合标准”
    - 负样本图片集（Negative Samples）：已确认“不符合标准”
    你可以同时查看并对比两类图片。

    # CORE METHODOLOGY（必须严格遵守）
    1. **正向归纳**  
       - 观察正样本，找出反复出现的视觉特征（姿态、结构、比例、肌肉状态、面部细节、光影、构图等）。
    2. **反向排除**  
       - 与负样本进行对比，剔除那些在正负样本中同时存在的“非判别性特征”。
    3. **差异聚焦**  
       - 仅保留“正样本显著存在、负样本显著缺失或相反”的视觉信号。
    4. **微特征强制挖掘（硬性要求）**  
       - 即使整体特征不明显，也必须深入分析：
         - 面部微表情
         - 肌肉走向与张力
         - 视线方向与聚焦状态
         - 身体开放/收缩程度
         - 情绪张力、节律或动态暗示
    5. **规则抽象**  
       - 将视觉差异上升为**稳定、可迁移的判断规则**，避免具体到某一张图片。
       
    # RULE DESIGN REQUIREMENTS（强约束）
    - ❌ 不允许返回空规则
    - ❌ 不允许使用“可能、看起来像、大概”等模糊表述
    - ✅ 至少输出 **3 条** 判断规则
    - ✅ 每条规则必须：
      - 可被用于判断“是否符合标准”
      - 不依赖文字、标签或上下文，只依赖图像本身
      - 描述为「如果观察到 X，则更可能属于正样本」
    # OUTPUT FORMAT（必须严格遵守）
    仅以 JSON 形式输出，不要附加任何解释性文字。

    ```json
    {{
      "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
      "rule_list": [
        {{
          "rule_id": "R1",
          "visual_signal": "具体可观察的视觉信号描述",
          "positive_pattern": "正样本中该信号通常如何呈现",
          "judgement_logic": "该信号为何能够区分正负样本（因果或经验逻辑）"
        }}
      ]
    }}
        """
```

![截屏2026-01-07 14.11.28.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/e4aa2bc4-60cd-4846-86dd-8288a96d4f01.png)

完整化agent1工作流

```plaintext


# ==========================================
# 1. 配置中心
# ==========================================
CONFIG = {
    "API_KEY": "sk-djgFaFYUKXko0gDChJFRxxjJ7bpn8RibevAzJphuYZPw76ET", 
    "BASE_URL": "https://www.dmxapi.com/v1", 
    "INDUSTRY_TOPIC": "憎恶的表情图片", 
    "PATHS": {
        "TRAIN_POS": "./训练集憎恶正例",
        "TRAIN_NEG": "./训练集憎恶负例",
        "TEST_POS": "./测试集憎恶正例",
        "TEST_NEG": "./测试集憎恶负例",
    },
    "MODEL": "Qwen3-VL-235B-A22B-Instruct" 
}


# 初始化客户端
client = OpenAI(api_key=CONFIG["API_KEY"].strip(), base_url=CONFIG["BASE_URL"].strip())

# ==========================================
# 2. 工具函数
# ==========================================
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def load_images_safe(folder_path, label):
    """安全读取图片并返回base64列表"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        print(f"⚠️ 文件夹已创建但目前为空: {folder_path}，请放入{label}图片后重新运行。")
        return []
    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    print(f"📂 已加载 {label}: {len(files)} 张图片")
    # 限制训练集读取张数防止Token溢出，测试集不限
    limit = 8 if "训练" in label else 100
    return [encode_image(os.path.join(folder_path, f)) for f in files[:limit]]

def parse_score_json(json_str):
    """鲁棒的JSON解析，兼容中英文键名"""
    try:
        d = json.loads(json_str)
        scores_part = d.get("scores", d)
        def find_s(keys):
            for k, v in scores_part.items():
                if any(ik in k.lower() for ik in keys): return v
            return 0
        return {
            "logic": find_s(["logic", "逻辑"]),
            "relevance": find_s(["relevance", "相关", "业务"]),
            "completeness": find_s(["completeness", "完备", "覆盖"]),
            "operability": find_s(["operability", "操作", "执行"]),
            "total": d.get("total_score", d.get("总分", 0))
        }
    except:
        return {"logic":0, "relevance":0, "completeness":0, "operability":0, "total":0}

# ==========================================
# 3. 核心判定逻辑 (Agent 0, 4)
# ==========================================
def perform_test(rules_text, pos_list, neg_list, is_zero_shot=False):
    """在测试集上运行P/R测试"""
    tp, fp, tn, fn = 0, 0, 0, 0
    if is_zero_shot:
        prompt = f"# ROLE: 通用视觉判定专家\n# CONTEXT: 仅凭常识判定图片是否符合主题：{CONFIG['INDUSTRY_TOPIC']}。\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"
    else:
        prompt = f"# ROLE: 规则执行官\n# RULE: {rules_text}\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"

    for img in pos_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): tp += 1
        else: fn += 1
    for img in neg_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): fp += 1
        else: tn += 1
    
    p = tp/(tp+fp) if (tp+fp)>0 else 0
    r = tp/(tp+fn) if (tp+fn)>0 else 0
    return p, r

# ==========================================
# 4. 主工作流
# ==========================================
def run_workflow():
    # A. 数据加载
    print("🎬 正在初始化数据...")
    train_pos = load_images_safe(CONFIG["PATHS"]["TRAIN_POS"], "训练集正例")
    train_neg = load_images_safe(CONFIG["PATHS"]["TRAIN_NEG"], "训练集负例")
    test_pos = load_images_safe(CONFIG["PATHS"]["TEST_POS"], "测试集正例")
    test_neg = load_images_safe(CONFIG["PATHS"]["TEST_NEG"], "测试集负例")

    if not train_pos or not train_neg or not test_pos or not test_neg:
        print("🛑 错误：文件夹图片不足，请准备好图片后再运行。")
        return

    # --- 阶段 0: 零启动测试 ---
    print("🔍 阶段 0: 零启动测试（基于测试集）...")
    zs_p, zs_r = perform_test(None, test_pos, test_neg, is_zero_shot=True)

    # --- 阶段 1: Agent 1 (初始规则) ---
    print("🤖 阶段 1: Agent 1 提炼初始规则...")
    prompt1 = f"""
    # ROLE
    - 你是一名资深的【计算机视觉特征工程专家】与【行业逻辑架构师】。
    - 你的任务是：基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。

    # LOGIC PHILOSOPHY
    - **保留潜在元素**：即使某个特征在负样本中也存在，只要它可能是构成判定组合的一部分，就必须保留。
    - **证伪驱动修正**：将正样本中提取的“初版规则”放在负样本中运行，若误判，则通过增加约束条件（AND/NOT）来修正，而非直接删除特征。
    - **最小化路径**：在确保 100% 区分正负样本的前提下，规则描述应尽可能简洁。

    # INPUT
    - **Positive Samples**: 符合【{CONFIG['INDUSTRY_TOPIC']}】标准的图片集。
    - **Negative Samples**: 不符合标准的干扰项图片集。

    ---

    # EXPLICIT WORKFLOW

    ## STEP 1：正样本特征提取与规则初探 (Hypothesis Generation)
    - **视觉原点挖掘**：观察所有正样本，提取出所有显著的视觉元素（特征 A, B, C...）。
    - **内部共性组合**：分析这些特征如何组合（单点或多点组合）能覆盖 100% 的正样本。
    - **建立初版规则**：例如：“规则1 = A + B” 或 “规则2 = C”。

    ## STEP 2：负样本冲突测试 (Stress Testing & Conflict Detection)
    - **规则代入**：将 STEP 1 建立的初版规则逐一在负样本中测试。
    - **冲突记录**：如果负样本也触发了某条规则（即出现了 False Positive），详细记录该负样本在对应特征上的细微差异。
    - **识别判别增量**：寻找能将“触发规则的负样本”排除掉的额外视觉特征 D（即：在正样本中 A+B 且具备 D 属性，而负样本只有 A+B 但不具备 D）。

    ## STEP 3：动态修正与逻辑收敛 (Rule Refinement)
    - **规则打补丁**：利用 STEP 2 发现的增量，对初版规则进行加固。
      - *修正前*：Rule = A + B
      - *修正后*：Rule = A + B + (具备 D 属性/排除 E 环境)
    - **结构压缩**：检查修正后的规则，如果多个规则可以合并，或者某个特征在加入新约束后变得冗余，则进行精简。

    ## STEP 4：生成最终判定矩阵 (Final Synthesis)
    - 整理出一组相互独立且互补的规则，每条规则都是一条从视觉证据到判定的完整路径。

    ---

    # OUTPUT FORMAT (STRICT JSON ONLY)

    ```json
{{
  "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
  "visual_cues": [
    {{
      "cue_id": "C1",
      "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
    }}
  ],
  "decision_rules": [
    {{
      "rule_id": "R1",
      "logic": "C1 AND C2",
      "target": "POSITIVE"
    }},
    {{
      "rule_id": "R2",
      "logic": "C3 AND (NOT C4)",
      "target": "POSITIVE"
    }}
  ]
}}
        """
    c1 = [{"type": "text", "text": prompt1}, {"type": "text", "text": "=== 训练集正例 ==="}]
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c1.append({"type": "text", "text": "=== 训练集负例 ==="})
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])
    
    r1_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": c1}], response_format={"type": "json_object"})
    r1_content = r1_res.choices[0].message.content

    # --- 阶段 2: Agent 2 (挑战者) ---
    print("🕵️ 阶段 2: Agent 2 挑战规则...")
    prompt2 = f"""
    # ROLE: 逻辑漏洞审计员 (红队成员)
    # CONTEXT: 你需要通过观察原始图片，质疑智能体1提取的规则。寻找伪相关性。
    # WORKFLOW:
    1. 观察提供的【训练集正例】与【训练集负例】。
    2. 审查 INPUT_RULES 中是否存在“伪相关性”（即规则描述了正例中有但与主题无关的特征）。
    3. 检查规则是否过于模糊，导致无法区分正负样本。
    4. 提出至少3个挑战点。
    # INPUT_RULES: {r1_content}
    # OUTPUT STANDARD: JSON 格式输出 challenges 数组。
    """
    
    # 构建包含图片的输入
    c2 = [{"type": "text", "text": prompt2}, {"type": "text", "text": "=== 待审计的原始训练集正例 ==="}]
    c2.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c2.append({"type": "text", "text": "=== 待审计的原始训练集负例 ==="})
    c2.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])

    r2_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c2}], 
        response_format={"type": "json_object"}
    )
    r2_content = r2_res.choices[0].message.content

    # --- 阶段 3: Agent 3 (合成最终规则) ---
    print("⚖️ 阶段 3: Agent 3 合成最终规则...")
    prompt3 = f"""
    # ROLE: 行业标准首席架构师
    # CONTEXT: 你需要整合初步规则和挑战意见，并再次对照原始图片，输出最终的行业判别准则。
    # WORKFLOW: 
    1. 吸收初步规则 (INPUT_INITIAL)。
    2. 采纳合理的质疑意见 (INPUT_CHALLENGES)。
    3. 对照【训练集正例】与【训练集负例】图片，确保最终规则能完美区分两者。
    4. 重新定义规则。
    # INPUT_INITIAL: {r1_content}
    # INPUT_CHALLENGES: {r2_content}
    # OUTPUT STANDARD: JSON 格式输出 final_rules 数组。
    """

    # 构建包含图片的输入
    c3 = [{"type": "text", "text": prompt3}, {"type": "text", "text": "=== 参照对比：训练集正例 ==="}]
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c3.append({"type": "text", "text": "=== 参照对比：训练集负例 ==="})
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])

    r3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c3}], 
        response_format={"type": "json_object"}
    )
    r3_content = r3_res.choices[0].message.content

# ... (后续阶段 4 和结果汇总代码保持不变)

    # --- 阶段 4: Agent 4 评估 ---
    print("📊 阶段 4: Agent 4 进行审计与效能实测...")
    
    # 定义结构化 Prompt，明确 Key 的名称以防解析失败
    score_p_template = """
    # ROLE: 规则质量评估专家
    # WORKFLOW: 
    请对以下规则进行四个维度的量化打分（每个维度满分 25 分，总分 100 分）：
    1. 逻辑一致性：规则内部是否存在矛盾。
    2. 业务相关性：是否有效剔除了与主题无关的噪音（如背景、无关杂物）。
    3. 完备性：规则是否覆盖了区分正负样本的核心视觉信号。
    4. 可操作性：规则描述是否清晰，能否被第三方准确执行。
    
    # INPUT: 
    {rules_to_score}
    
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，不得包含解释文字。必须包含 "scores" 字典，其 Key 必须严格为: 
    "logic", "relevance", "completeness", "operability"。此外包含 "total_score"。
    """

    # 判定并生成初始规则评分 (使用 f-string 避免 .format 错误)
    s1_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r1_content)}"}], 
        response_format={"type":"json_object"}
    )
    s1_json = s1_res.choices[0].message.content
    
    # 判定并生成最终规则评分
    s3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r3_content)}"}], 
        response_format={"type":"json_object"}
    )
    s3_json = s3_res.choices[0].message.content

    # 解析数据 (确保你的 parse_score_json 函数能处理 logic, relevance 等 Key)
    s1_data = parse_score_json(s1_json)
    s3_data = parse_score_json(s3_json)
    
    # 效能实测 (仅基于测试集)
    r1_p, r1_r = perform_test(r1_content, test_pos, test_neg)
    r3_p, r3_r = perform_test(r3_content, test_pos, test_neg)

    # ==========================================
    # 5. 结果汇总输出
    # ==========================================
    print("\n" + "★"*40)
    print("【1. 智能体 1：初始规则内容】")
    print(r1_content)
    print("\n【2. 智能体 2：挑战意见】")
    print(r2_content)
    print("\n【3. 智能体 3：最终合成规则内容】")
    print(r3_content)
    
    print("\n【4. 综合进化对比表 (指标基于测试集)】")
    print("-" * 95)
    print(f"{'评估维度':<16} | {'零启动(Zero-Shot)':<18} | {'初始规则(Initial)':<18} | {'最终规则(Final)':<18}")
    print("-" * 95)
    
    rows = [("逻辑一致性","logic"), ("业务相关性","relevance"), ("完备性","completeness"), ("可操作性","operability"), ("内容总分","total")]
    for name, key in rows:
        v1, v3 = s1_data[key], s3_data[key]
        print(f"{name:<16} | {'--':<18} | {v1:<18} | {v3:<18}")
    
    print("-" * 95)
    print(f"{'精确率 (Prec.)':<16} | {zs_p:<18.2%} | {r1_p:<18.2%} | {r3_p:<18.2%}")
    print(f"{'召回率 (Rec.)':<16} | {zs_r:<18.2%} | {r1_r:<18.2%} | {r3_r:<18.2%}")
    print("-" * 95)

run_workflow()
```

![截屏2026-01-07 15.50.47.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/1a2ceca0-e19c-4f5d-9e2d-829037705f30.png)

优化agent1 prompt

在上一版的基础上进一步细化每一步的工作环节

```plaintext


# ==========================================
# 1. 配置中心
# ==========================================
CONFIG = {
    "API_KEY": "sk-djgFaFYUKXko0gDChJFRxxjJ7bpn8RibevAzJphuYZPw76ET", 
    "BASE_URL": "https://www.dmxapi.com/v1", 
    "INDUSTRY_TOPIC": "憎恶的表情图片", 
    "PATHS": {
        "TRAIN_POS": "./训练集憎恶正例",
        "TRAIN_NEG": "./训练集憎恶负例",
        "TEST_POS": "./测试集憎恶正例",
        "TEST_NEG": "./测试集憎恶负例",
    },
    "MODEL": "Qwen3-VL-235B-A22B-Instruct" 
}


# 初始化客户端
client = OpenAI(api_key=CONFIG["API_KEY"].strip(), base_url=CONFIG["BASE_URL"].strip())

# ==========================================
# 2. 工具函数
# ==========================================
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def load_images_safe(folder_path, label):
    """安全读取图片并返回base64列表"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        print(f"⚠️ 文件夹已创建但目前为空: {folder_path}，请放入{label}图片后重新运行。")
        return []
    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    print(f"📂 已加载 {label}: {len(files)} 张图片")
    # 限制训练集读取张数防止Token溢出，测试集不限
    limit = 8 if "训练" in label else 100
    return [encode_image(os.path.join(folder_path, f)) for f in files[:limit]]

def parse_score_json(json_str):
    """鲁棒的JSON解析，兼容中英文键名"""
    try:
        d = json.loads(json_str)
        scores_part = d.get("scores", d)
        def find_s(keys):
            for k, v in scores_part.items():
                if any(ik in k.lower() for ik in keys): return v
            return 0
        return {
            "logic": find_s(["logic", "逻辑"]),
            "relevance": find_s(["relevance", "相关", "业务"]),
            "completeness": find_s(["completeness", "完备", "覆盖"]),
            "operability": find_s(["operability", "操作", "执行"]),
            "total": d.get("total_score", d.get("总分", 0))
        }
    except:
        return {"logic":0, "relevance":0, "completeness":0, "operability":0, "total":0}

# ==========================================
# 3. 核心判定逻辑 (Agent 0, 4)
# ==========================================
def perform_test(rules_text, pos_list, neg_list, is_zero_shot=False):
    """在测试集上运行P/R测试"""
    tp, fp, tn, fn = 0, 0, 0, 0
    if is_zero_shot:
        prompt = f"# ROLE: 通用视觉判定专家\n# CONTEXT: 仅凭常识判定图片是否符合主题：{CONFIG['INDUSTRY_TOPIC']}。\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"
    else:
        prompt = f"# ROLE: 你是一个规则执行官，你首先需要依照{rules_text}判断图片是否符合主题【{CONFIG['INDUSTRY_TOPIC']}；随后再进行一次检查，然后再给出最终答案。\n# RULE: {rules_text}\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"

    for img in pos_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): tp += 1
        else: fn += 1
    for img in neg_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): fp += 1
        else: tn += 1
    
    p = tp/(tp+fp) if (tp+fp)>0 else 0
    r = tp/(tp+fn) if (tp+fn)>0 else 0
    return p, r

# ==========================================
# 4. 主工作流
# ==========================================
def run_workflow():
    # A. 数据加载
    print("🎬 正在初始化数据...")
    train_pos = load_images_safe(CONFIG["PATHS"]["TRAIN_POS"], "训练集正例")
    train_neg = load_images_safe(CONFIG["PATHS"]["TRAIN_NEG"], "训练集负例")
    test_pos = load_images_safe(CONFIG["PATHS"]["TEST_POS"], "测试集正例")
    test_neg = load_images_safe(CONFIG["PATHS"]["TEST_NEG"], "测试集负例")

    if not train_pos or not train_neg or not test_pos or not test_neg:
        print("🛑 错误：文件夹图片不足，请准备好图片后再运行。")
        return

    # --- 阶段 0: 零启动测试 ---
    print("🔍 阶段 0: 零启动测试（基于测试集）...")
    zs_p, zs_r = perform_test(None, test_pos, test_neg, is_zero_shot=True)

    # --- 阶段 1: Agent 1 (初始规则) ---
    print("🤖 阶段 1: Agent 1 提炼初始规则...")
    prompt1 = f"""
    # ROLE
    - 你是一名资深的【计算机视觉特征工程专家】与【行业逻辑架构师】。
    - 你的任务是：基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。

    # LOGIC PHILOSOPHY
    - **保留潜在元素**：即使某个特征在负样本中也存在，只要它可能是构成判定组合的一部分，就必须保留。
    - **证伪驱动修正**：将正样本中提取的“初版规则”放在负样本中运行，若误判，则通过增加约束条件（AND/NOT）来修正，而非直接删除特征。
    - **最小化路径**：在确保 100% 区分正负样本的前提下，规则描述应尽可能简洁。

    # INPUT
    - **Positive Samples**: 符合【{CONFIG['INDUSTRY_TOPIC']}】标准的图片集。
    - **Negative Samples**: 不符合标准的干扰项图片集。

    ---

    # EXPLICIT WORKFLOW

    ## STEP 1：正样本特征提取与规则初探 (Hypothesis Generation)
    - **视觉原点挖掘**：观察所有正样本，提取出所有显著的视觉元素（特征 A, B, C...）。
    - **内部共性组合**：分析这些特征如何组合（单点或多点组合）能覆盖 100% 的正样本。
    - **建立初版规则**：例如：“规则1 = A + B” 或 “规则2 = C”。

    ## STEP 2：负样本冲突测试 (Stress Testing & Conflict Detection)
    - **规则代入**：将 STEP 1 建立的初版规则逐一在负样本中测试。
    - **冲突记录**：如果负样本也触发了某条规则（即出现了 False Positive），详细记录该负样本在对应特征上的细微差异。
    - **识别判别增量**：寻找能将“触发规则的负样本”排除掉的额外视觉特征 D（即：在正样本中 A+B 且具备 D 属性，而负样本只有 A+B 但不具备 D）。

    ## STEP 3：动态修正与逻辑收敛 (Rule Refinement)
    - **规则打补丁**：利用 STEP 2 发现的增量，对初版规则进行加固。
      - *修正前*：Rule = A + B
      - *修正后*：Rule = A + B + (具备 D 属性/排除 E 环境)
    - **结构压缩**：检查修正后的规则，如果多个规则可以合并，或者某个特征在加入新约束后变得冗余，则进行精简。

    ## STEP 4：生成最终判定矩阵 (Final Synthesis)
    - 整理出一组相互独立且互补的规则，每条规则都是一条从视觉证据到判定的完整路径。

    ---

    # OUTPUT FORMAT (STRICT JSON ONLY)

    ```json
{{
  "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
  "visual_cues": [
    {{
      "cue_id": "C1",
      "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
    }}
  ],
  "decision_rules": [
    {{
      "rule_id": "R1",
      "logic": "C1 AND C2",
      "target": "POSITIVE"
    }},
    {{
      "rule_id": "R2",
      "logic": "C3 AND (NOT C4)",
      "target": "POSITIVE"
    }}
  ]
}}
        """
    c1 = [{"type": "text", "text": prompt1}, {"type": "text", "text": "=== 训练集正例 ==="}]
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c1.append({"type": "text", "text": "=== 训练集负例 ==="})
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])
    
    r1_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": c1}], response_format={"type": "json_object"})
    r1_content = r1_res.choices[0].message.content

    # --- 阶段 2: Agent 2 (挑战者) ---
    print("🕵️ 阶段 2: Agent 2 开始审计规则逻辑与伪相关性...")
    # 1. 优化后的通用 Prompt
    prompt2 = f"""
    # ROLE
    - 你是一个逻辑漏洞审计员 (红队成员)
    - 你需要审核**行业逻辑架构师**从图像集中提取的【分类规则】。你的目标是发现规则中的逻辑漏洞、过度拟合以及“伪相关性”（Spurious Correlations）。

    # DEFINITION 
    - 【训练集正例】：完全符合目标类别的标准样本。
    - 【训练集负例】：不符合目标类别的样本，必须被规则准确排除。
    - **行业逻辑架构师**：其任务是基于正负样本对比，发现判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    
    # INPUT_RULES: {r1_content}
    
    # WORKFLOW:
    ## Step 1: **对比观察**
    - 结合正例与负例图片，逐条审查 INPUT_RULES。
    
    ##Step 2: **多维度审计**：
    - 从以下维度评价INPUT_RULES，并针对存在问题的部分提出质疑和反驳
        - 逻辑一致性：规则不应存在内部矛盾
        - 有效性：规则应能逻辑严密地覆盖所有正例并剔除所有负例
        - 伪相关性：规则不应包含与【{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
        - 过度拟合：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    # CONSTRAITS:
    - 你必须严格围绕INPUT_RULES和正负例图片进行分析，不要过度依靠你关于【{CONFIG['INDUSTRY_TOPIC']}】的个性化解度
    - 严禁为了反驳而反驳，你的每一条反驳必须有理有据。
    

    # OUTPUT STANDARD:
    必须以 JSON 格式输出，包含 challenges 数组，结构如下：
    {{
      "challenges": [
        {{
          "target_rule": "被质疑的原始规则条目",
          "logic_error_type": "逻辑一致性 / 有效性/ 伪相关性/过度拟合",
          "reasoning": "解释为什么利用该特征作为判定依据是不可靠的。"
        }}
      ]
    }}
    """

    # 2. 构建包含图像序列的输入
    c2 = [{"type": "text", "text": prompt2}]

    # 辅助说明，确保模型明确图像的标签身份
    c2.append({"type": "text", "text": "=== 待审计的【训练集正例】 (Target Category Samples) ==="})
    for img_data in train_pos:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    c2.append({"type": "text", "text": "=== 待审计的【训练集负例】 (Negative Samples) ==="})
    for img_data in train_neg:
        c2.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_data}", "detail": "low"}})

    # 3. 执行 API 调用
    r2_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c2}], 
        response_format={"type": "json_object"}
    )

    r2_content = r2_res.choices[0].message.content

    # --- 阶段 3: Agent 3 (合成最终规则) ---
    print("⚖️ 阶段 3: Agent 3 合成最终规则...")
    prompt3 = f"""
    # ROLE
    - 你是一位行业标准首席架构师
    - 你需要判断挑战意见的合理性，并再次对照原始图片，优化和调整初步规则，形成最终的行业判别准则。
    # Definition：
    - **初步规则**：由一位行业逻辑架构师对比正负样本，发现的判断【{CONFIG['INDUSTRY_TOPIC']}】所需的**最小充分视觉规则**。
    - **挑战意见**：由一位审计人员对比正负样本和**初步规则**提出的挑战性建议。
    - **逻辑一致性**：规则不应存在内部矛盾
    - **有效性**：规则应能逻辑严密地覆盖所有正例并剔除所有负例
    - **伪相关性**：规则不应包含与{CONFIG['INDUSTRY_TOPIC']}】本质无关的特征（如背景、画质、光线、是否静态、拍摄角度等）
    - **过度拟合**：规则不应为了排除特定的负例，而设定了过于严苛、会导致未来“正例被误杀”的限制条件

    
    # INPUT_INITIAL: {r1_content}
    # INPUT_CHALLENGES: {r2_content}
    
    # WORKFLOW: 
    ## Step 1: 综合理解
    - 对照【训练集正例】与【训练集负例】图片，全面理解阅读**初步规则 (INPUT_INITIAL)**、**挑战意见 (INPUT_CHALLENGES)**。
    ## Step 2: **挑战意见**审核
    - 从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度，理性判断**挑战意见**的合理性
    - 仅保留“挑战意见”中合理的部分。
    ## Step 3: **行业判别标准**生成
    - 结合**挑战意见**中合理的部分，优化**初步规则**，形成**行业判别标准**。
    ## Step 4: 双重校验
    - 再次基于【训练集正例】与【训练集负例】图片，从**逻辑一致性**、**有效性**、**伪相关性**和**过度拟合**的角度评价**行业判别标准**。若符合标准则输出；若不符合标准则继续优化。
    
    # CONSTRAITS:
    - 严禁盲信**挑战意见**的观点，你是老板，你优最终选择权。

    # OUTPUT STANDARD: 以JSON 格式输出 final_rules 数组，结构如下：
    {{
      "industry_topic": "{CONFIG['INDUSTRY_TOPIC']}",
      "visual_cues": [
        {{
          "cue_id": "C1",
          "description": "具体物理特征描述（如：表面有网格状纹理、存在特定颜色的标识、组件边缘呈直角）"
        }}
      ],
      "decision_rules": [
        {{
          "rule_id": "R1",
          "logic": "C1 AND C2",
          "target": "POSITIVE"
        }},
        {{
          "rule_id": "R2",
          "logic": "C3 AND (NOT C4)",
          "target": "POSITIVE"
        }}
      ]
    }}
        """

    # 构建包含图片的输入
    c3 = [{"type": "text", "text": prompt3}, {"type": "text", "text": "=== 参照对比：训练集正例 ==="}]
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c3.append({"type": "text", "text": "=== 参照对比：训练集负例 ==="})
    c3.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])

    r3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role": "user", "content": c3}], 
        response_format={"type": "json_object"}
    )
    r3_content = r3_res.choices[0].message.content

# ... (后续阶段 4 和结果汇总代码保持不变)

    # --- 阶段 4: Agent 4 评估 ---
    print("📊 阶段 4: Agent 4 进行审计与效能实测...")
    
    # 定义结构化 Prompt，明确 Key 的名称以防解析失败
    score_p_template = """
    # ROLE: 规则质量评估专家
    # WORKFLOW: 
    请对以下规则进行四个维度的量化打分（每个维度满分 25 分，总分 100 分）：
    1. 逻辑一致性：规则内部是否存在矛盾。
    2. 业务相关性：是否有效剔除了与主题无关的噪音（如背景、无关杂物）。
    3. 完备性：规则是否覆盖了区分正负样本的核心视觉信号。
    4. 可操作性：规则描述是否清晰，能否被第三方准确执行。
    
    # INPUT: 
    {rules_to_score}
    
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，不得包含解释文字。必须包含 "scores" 字典，其 Key 必须严格为: 
    "logic", "relevance", "completeness", "operability"。此外包含 "total_score"。
    """

    # 判定并生成初始规则评分 (使用 f-string 避免 .format 错误)
    s1_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r1_content)}"}], 
        response_format={"type":"json_object"}
    )
    s1_json = s1_res.choices[0].message.content
    
    # 判定并生成最终规则评分
    s3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r3_content)}"}], 
        response_format={"type":"json_object"}
    )
    s3_json = s3_res.choices[0].message.content

    # 解析数据 (确保你的 parse_score_json 函数能处理 logic, relevance 等 Key)
    s1_data = parse_score_json(s1_json)
    s3_data = parse_score_json(s3_json)
    
    # 效能实测 (仅基于测试集)
    r1_p, r1_r = perform_test(r1_content, test_pos, test_neg)
    r3_p, r3_r = perform_test(r3_content, test_pos, test_neg)

    # ==========================================
    # 5. 结果汇总输出
    # ==========================================
    print("\n" + "★"*40)
    print("【1. 智能体 1：初始规则内容】")
    print(r1_content)
    print("\n【2. 智能体 2：挑战意见】")
    print(r2_content)
    print("\n【3. 智能体 3：最终合成规则内容】")
    print(r3_content)
    
    print("\n【4. 综合进化对比表 (指标基于测试集)】")
    print("-" * 95)
    print(f"{'评估维度':<16} | {'零启动(Zero-Shot)':<18} | {'初始规则(Initial)':<18} | {'最终规则(Final)':<18}")
    print("-" * 95)
    
    rows = [("逻辑一致性","logic"), ("业务相关性","relevance"), ("完备性","completeness"), ("可操作性","operability"), ("内容总分","total")]
    for name, key in rows:
        v1, v3 = s1_data[key], s3_data[key]
        print(f"{name:<16} | {'--':<18} | {v1:<18} | {v3:<18}")
    
    print("-" * 95)
    print(f"{'精确率 (Prec.)':<16} | {zs_p:<18.2%} | {r1_p:<18.2%} | {r3_p:<18.2%}")
    print(f"{'召回率 (Rec.)':<16} | {zs_r:<18.2%} | {r1_r:<18.2%} | {r3_r:<18.2%}")
    print("-" * 95)

run_workflow()
```

![截屏2026-01-07 17.56.58.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/b1ac2366-07ff-441f-92ec-35762f878e51.png)

优化agent2 和agent 3 的prompt，并调整测试prompt的内容。

![截屏2026-01-07 18.01.15.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/9cfcc805-0f07-4d66-ba5c-59ba974180f7.png)

# 0106

今日正式开始对整个知识提取的工作流展开测试

```plaintext


# ==========================================
# 1. 配置中心
# ==========================================
CONFIG = {
    "API_KEY": "", 
    "BASE_URL": "", 
    "INDUSTRY_TOPIC": "憎恶的表情图片", 
    "PATHS": {
        "TRAIN_POS": "./训练集憎恶正例",
        "TRAIN_NEG": "./训练集憎恶负例",
        "TEST_POS": "./测试集憎恶正例",
        "TEST_NEG": "./测试集憎恶负例",
    },
    "MODEL": "Qwen3-VL-235B-A22B-Instruct" 
}


# 初始化客户端
client = OpenAI(api_key=CONFIG["API_KEY"].strip(), base_url=CONFIG["BASE_URL"].strip())

# ==========================================
# 2. 工具函数
# ==========================================
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def load_images_safe(folder_path, label):
    """安全读取图片并返回base64列表"""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        print(f"⚠️ 文件夹已创建但目前为空: {folder_path}，请放入{label}图片后重新运行。")
        return []
    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    print(f"📂 已加载 {label}: {len(files)} 张图片")
    # 限制训练集读取张数防止Token溢出，测试集不限
    limit = 8 if "训练" in label else 100
    return [encode_image(os.path.join(folder_path, f)) for f in files[:limit]]

def parse_score_json(json_str):
    """鲁棒的JSON解析，兼容中英文键名"""
    try:
        d = json.loads(json_str)
        scores_part = d.get("scores", d)
        def find_s(keys):
            for k, v in scores_part.items():
                if any(ik in k.lower() for ik in keys): return v
            return 0
        return {
            "logic": find_s(["logic", "逻辑"]),
            "relevance": find_s(["relevance", "相关", "业务"]),
            "completeness": find_s(["completeness", "完备", "覆盖"]),
            "operability": find_s(["operability", "操作", "执行"]),
            "total": d.get("total_score", d.get("总分", 0))
        }
    except:
        return {"logic":0, "relevance":0, "completeness":0, "operability":0, "total":0}

# ==========================================
# 3. 核心判定逻辑 (Agent 0, 4)
# ==========================================
def perform_test(rules_text, pos_list, neg_list, is_zero_shot=False):
    """在测试集上运行P/R测试"""
    tp, fp, tn, fn = 0, 0, 0, 0
    if is_zero_shot:
        prompt = f"# ROLE: 通用视觉判定专家\n# CONTEXT: 仅凭常识判定图片是否符合主题：{CONFIG['INDUSTRY_TOPIC']}。\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"
    else:
        prompt = f"# ROLE: 规则执行官\n# RULE: {rules_text}\n# OUTPUT: 符合回复 'YES'，不符合回复 'NO'。只输出一个单词。"

    for img in pos_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): tp += 1
        else: fn += 1
    for img in neg_list:
        res = client.chat.completions.create(
            model=CONFIG["MODEL"],
            messages=[{"role":"user","content":[{"type":"text","text":prompt},{"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img}"}}]}]
        )
        if "YES" in res.choices[0].message.content.strip().upper(): fp += 1
        else: tn += 1
    
    p = tp/(tp+fp) if (tp+fp)>0 else 0
    r = tp/(tp+fn) if (tp+fn)>0 else 0
    return p, r

# ==========================================
# 4. 主工作流
# ==========================================
def run_workflow():
    # A. 数据加载
    print("🎬 正在初始化数据...")
    train_pos = load_images_safe(CONFIG["PATHS"]["TRAIN_POS"], "训练集正例")
    train_neg = load_images_safe(CONFIG["PATHS"]["TRAIN_NEG"], "训练集负例")
    test_pos = load_images_safe(CONFIG["PATHS"]["TEST_POS"], "测试集正例")
    test_neg = load_images_safe(CONFIG["PATHS"]["TEST_NEG"], "测试集负例")

    if not train_pos or not train_neg or not test_pos or not test_neg:
        print("🛑 错误：文件夹图片不足，请准备好图片后再运行。")
        return

    # --- 阶段 0: 零启动测试 ---
    print("🔍 阶段 0: 零启动测试（基于测试集）...")
    zs_p, zs_r = perform_test(None, test_pos, test_neg, is_zero_shot=True)

    # --- 阶段 1: Agent 1 (初始规则) ---
    print("🤖 阶段 1: Agent 1 提炼初始规则...")
    prompt1 = f"""
    # ROLE: 视觉特征归纳专家
    # CONTEXT: 用户希望从一组正向样本和负向样本中，总结出判断【{CONFIG['INDUSTRY_TOPIC']}】特征的标准。
    # WORKFLOW:
    1. 观察正例图片组，识别其共同的视觉特征。
    2. 对比负例图片组，排除通用特征。
    3. 提炼出仅属于正例的特有判断规则。
    4. 【硬性要求】：严禁返回空列表。即使特征不显著，也必须挖掘面部微表情、肌肉走向或神态中的微弱信号，归纳出至少 3 条判定规则。
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，包含 rule_list 数组。
    """
    c1 = [{"type": "text", "text": prompt1}, {"type": "text", "text": "=== 训练集正例 ==="}]
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_pos])
    c1.append({"type": "text", "text": "=== 训练集负例 ==="})
    c1.extend([{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{i}", "detail": "low"}} for i in train_neg])
    
    r1_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": c1}], response_format={"type": "json_object"})
    r1_content = r1_res.choices[0].message.content

    # --- 阶段 2: Agent 2 (挑战者) ---
    print("🕵️ 阶段 2: Agent 2 挑战规则...")
    prompt2 = f"""
    # ROLE: 逻辑漏洞审计员 (红队成员)
    # CONTEXT: 质疑智能体1提取的规则。寻找伪相关性。
    # WORKFLOW:
    1. 审查规则中是否存在“伪相关性”。
    2. 检查规则是否过于模糊。
    3. 提出至少3个挑战点。
    4. 【硬性要求】：严禁返回空列表。即使特征不显著，也必须挖掘面部微表情、肌肉走向或神态中的微弱信号，归纳出至少 3 条判定规则。
    # INPUT_RULES: {r1_content}
    # OUTPUT STANDARD: JSON 格式输出 challenges 数组。
    """
    r2_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": prompt2}], response_format={"type": "json_object"})
    r2_content = r2_res.choices[0].message.content

    # --- 阶段 3: Agent 3 (合成最终规则) ---
    print("⚖️ 阶段 3: Agent 3 合成最终规则...")
    prompt3 = f"""
    # ROLE: 行业标准首席架构师
    # CONTEXT: 你需要整合初步规则和挑战意见，输出最终的行业判别准则。
    # WORKFLOW: 1.吸收发现 2.采纳质疑 3.重新定义规则。
    # INPUT_INITIAL: {r1_content}
    # INPUT_CHALLENGES: {r2_content}
    # OUTPUT STANDARD: JSON 格式输出 final_rules 数组。
    """
    r3_res = client.chat.completions.create(model=CONFIG["MODEL"], messages=[{"role": "user", "content": prompt3}], response_format={"type": "json_object"})
    r3_content = r3_res.choices[0].message.content

    # --- 阶段 4: Agent 4 评估 ---
    print("📊 阶段 4: Agent 4 进行审计与效能实测...")
    
    # 定义结构化 Prompt，明确 Key 的名称以防解析失败
    score_p_template = """
    # ROLE: 规则质量评估专家
    # WORKFLOW: 
    请对以下规则进行四个维度的量化打分（每个维度满分 25 分，总分 100 分）：
    1. 逻辑一致性：规则内部是否存在矛盾。
    2. 业务相关性：是否有效剔除了与主题无关的噪音（如背景、无关杂物）。
    3. 完备性：规则是否覆盖了区分正负样本的核心视觉信号。
    4. 可操作性：规则描述是否清晰，能否被第三方准确执行。
    
    # INPUT: 
    {rules_to_score}
    
    # OUTPUT STANDARD: 
    必须以 JSON 格式输出，不得包含解释文字。必须包含 "scores" 字典，其 Key 必须严格为: 
    "logic", "relevance", "completeness", "operability"。此外包含 "total_score"。
    """

    # 判定并生成初始规则评分 (使用 f-string 避免 .format 错误)
    s1_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r1_content)}"}], 
        response_format={"type":"json_object"}
    )
    s1_json = s1_res.choices[0].message.content
    
    # 判定并生成最终规则评分
    s3_res = client.chat.completions.create(
        model=CONFIG["MODEL"], 
        messages=[{"role":"user","content": f"# ROLE: 规则评估专家\n{score_p_template.replace('{rules_to_score}', r3_content)}"}], 
        response_format={"type":"json_object"}
    )
    s3_json = s3_res.choices[0].message.content

    # 解析数据 (确保你的 parse_score_json 函数能处理 logic, relevance 等 Key)
    s1_data = parse_score_json(s1_json)
    s3_data = parse_score_json(s3_json)
    
    # 效能实测 (仅基于测试集)
    r1_p, r1_r = perform_test(r1_content, test_pos, test_neg)
    r3_p, r3_r = perform_test(r3_content, test_pos, test_neg)

    # ==========================================
    # 5. 结果汇总输出
    # ==========================================
    print("\n" + "★"*40)
    print("【1. 智能体 1：初始规则内容】")
    print(r1_content)
    print("\n【2. 智能体 2：挑战意见】")
    print(r2_content)
    print("\n【3. 智能体 3：最终合成规则内容】")
    print(r3_content)
    
    print("\n【4. 综合进化对比表 (指标基于测试集)】")
    print("-" * 95)
    print(f"{'评估维度':<16} | {'零启动(Zero-Shot)':<18} | {'初始规则(Initial)':<18} | {'最终规则(Final)':<18}")
    print("-" * 95)
    
    rows = [("逻辑一致性","logic"), ("业务相关性","relevance"), ("完备性","completeness"), ("可操作性","operability"), ("内容总分","total")]
    for name, key in rows:
        v1, v3 = s1_data[key], s3_data[key]
        print(f"{name:<16} | {'--':<18} | {v1:<18} | {v3:<18}")
    
    print("-" * 95)
    print(f"{'精确率 (Prec.)':<16} | {zs_p:<18.2%} | {r1_p:<18.2%} | {r3_p:<18.2%}")
    print(f"{'召回率 (Rec.)':<16} | {zs_r:<18.2%} | {r1_r:<18.2%} | {r3_r:<18.2%}")
    print("-" * 95)

run_workflow()
```

## 一、Agent工作流1.0

Agent1：根据看到的训练集图片正例和负例，提取初识规则。

Agent2：根据Agent1返回的规则进行反驳，寻找伪相关性。

Agent3：综合Agent1和Agent2的规则，输出最终规则。

规则->图

Agent4：基于零启动、初识规则和最终规则三种情况，在测试集上进行实验，得到四维内容性评分（逻辑一致性、业务相关性、完备性、可操作性）和精确率、召回率的指标。

## 二、实验方法

今日采取了2 x 2的实验方法。

从数据维度，构建了两大类实验（咸鱼了一个数据包）。一类是开心图片的识别，负例是若干其他情绪的图片。另一类是憎恶图片的识别，负例是容易混淆的生气表情。从正例的识别难度和负例的易混淆程度而言，都是后者更高。——训练集正负例皆为5张照片，测试集皆为10张照片

从模型选择，选择了当前识别能力较强的Qwen3-VL-235B-A22B-Instruct和相对较弱的qwen2.5-vl-7b-instruct

## 三、数据表现

开心+Qwen3-VL-235B-A22B-Instruct

![截屏2026-01-06 22.27.21.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/d2c0b74d-eded-41bf-ae4e-0273510466fb.png)

开心+qwen2.5-vl-7b-instruct

![截屏2026-01-06 22.27.52.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/dd257e84-e029-491a-bbb6-a32b96d21491.png)

憎恶+Qwen3-VL-235B-A22B-Instruct

![截屏2026-01-06 22.28.26.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/7485d13f-49b4-4997-9729-5ef4721c5bf8.png)

憎恶+qwen2.5-vl-7b-instruct

![截屏2026-01-06 22.28.45.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/4j6OJ5jmoYQWbq3p/img/d5ce85a9-324d-4268-87a4-6c124d6bcf39.png)

## 四、今日结论

1.  对比“开心”和“憎恶”可知，难度较低、推理较容易的议题中，原本基座模型的训练数据中就包括的了大量的相关知识，少量图片提炼的规则反而容易干扰模型原本的判断，——希望能够获得某一个循证标签的数据
    
2.  对比Qwen3-VL-235B-A22B-Instruct和qwen2.5-vl-7b-instruct，前者的零启动识别能力未必更强，但是通过图片归纳规则的逻辑能力，明显前者更强。且当归纳轮数变多，弱项将更加明显。——后续可以尝试在图像识别和规则判断采用不同的模型
    
3.  “憎恶”场景中，对比零启动和初识规则的表现，当模型归纳能力强且议题较难时，图片提取的规则可以提高准确率和召回率。——进一步迭代此处的prompt
    
4.  在每一个场景中，当加入了反对者角色后，规则的质量都会显著下降。其可能的原因在于反对者和规则归纳者两个agent目前都仅仅基于规则进行判断，而没有结合图片，所以及其容易出现脱离图片本身的反驳和延伸。该问题为下一阶段优化的重中之重